{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import random\n",
    "from numba import jit\n",
    "pd.set_option('display.max_columns', 50)\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "class MonkeyBot(object):\n",
    "    def __init__(self, dfEnv, cash=1000, share=0, pv=0, now_yes_share=0):\n",
    "        self.cash = cash\n",
    "        self.share = share\n",
    "        self.pv = pv\n",
    "        self.asset_history_list = []\n",
    "        self.action_list = []\n",
    "        \n",
    "        self.env = deepcopy(dfEnv)\n",
    "\n",
    "    def buy(self, stock_price, cost, fold=1):\n",
    "        if self.cash < stock_price:\n",
    "            self.hold(stock_price)\n",
    "            \n",
    "        else:\n",
    "            num_affordable = int(self.cash // stock_price)\n",
    "            buy_amount = int(num_affordable // fold)\n",
    "            self.cash = self.cash - stock_price * buy_amount\n",
    "            self.share = self.share + buy_amount\n",
    "            self.pv = stock_price * self.share\n",
    "\n",
    "             # Adding transaction cost\n",
    "            self.trading_cost(buy_amount, cost)\n",
    "            \n",
    "            # Append action to action list\n",
    "            self.action_list.append('Buy' + str(fold))\n",
    "\n",
    "    def sell(self, stock_price, cost, fold=1):\n",
    "        if self.share == 0:\n",
    "            self.hold(stock_price)\n",
    "            \n",
    "        else:\n",
    "            sell_amount = int(self.share // fold)\n",
    "            self.cash = self.cash + stock_price * sell_amount\n",
    "            self.pv = 0\n",
    "            self.share = 0\n",
    "\n",
    "            # Adding transaction cost\n",
    "            self.trading_cost(sell_amount, cost)\n",
    "            \n",
    "            self.action_list.append('Sell' + str(fold))\n",
    "\n",
    "    def hold(self, stock_price):\n",
    "        self.pv = stock_price * self.share\n",
    "        self.action_list.append('Hold')\n",
    "\n",
    "    def trading_cost(self, trading_amount, cost):\n",
    "            if cost is None:\n",
    "                pass                \n",
    "            elif cost == 'low':\n",
    "                if trading_amount * 0.01 < 1.99:\n",
    "                    self.cash = self.cash - 1.99\n",
    "                else:\n",
    "                    self.cash = self.cash - trading_amount * 0.01\n",
    "            elif cost == 'medium':\n",
    "                if trading_amount * 0.01 < 5:\n",
    "                    self.cash = self.cash - 5\n",
    "                else:\n",
    "                    self.cash = self.cash - trading_amount * 0.01\n",
    "            elif cost == 'high':\n",
    "                if trading_amount * 0.01 < 7:\n",
    "                    self.cash = self.cash - 7\n",
    "                else:\n",
    "                    self.cash = self.cash - trading_amount * 0.01\n",
    "            else:\n",
    "                raise ValueError(\"Wrong cost parameter!\")\n",
    "        \n",
    "    def reset(self):\n",
    "        self.cash = 1000\n",
    "        self.share = 0\n",
    "        self.pv = 0\n",
    "\n",
    "    def yes_share(self):\n",
    "        # Represent chimp asset in state_action\n",
    "        if self.share > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def make_decision(self, x, cost):\n",
    "        random_choice = random.choice([1, 2])\n",
    "\n",
    "        if random_choice == 0:\n",
    "            self.hold(x)\n",
    "        elif random_choice == 1:\n",
    "            self.buy(x, cost)\n",
    "        else:\n",
    "            self.sell(x, cost)\n",
    "\n",
    "        return self.pv # for frame-wise operation\n",
    "\n",
    "    def simulate(self, iters, cost=None):\n",
    "        start_time = time.time()\n",
    "        for i in range(iters):\n",
    "            for index, row in self.env.iterrows():\n",
    "                self.make_decision(row['Trade Price'], cost)\n",
    "            self.asset_history_list.append(self.pv + self.cash)\n",
    "            self.reset()\n",
    "        print(\"{0} iterations took {1} seconds\".format(iters, time.time() - start_time))\n",
    "        \n",
    "        return self.asset_history_list, self.action_list\n",
    "\n",
    "class macdChimpBot(MonkeyBot):\n",
    "    \"\"\"An agent that learns to drive in the smartcab world.\"\"\"\n",
    "    valid_actions = ['Buy', 'Sell', 'Hold']\n",
    "\n",
    "    num_trial = 500\n",
    "    trial_counter = 0 # For getting the trial number\n",
    "\n",
    "    trial_meta_info = {} # For monitoring what happens in each trial\n",
    "\n",
    "    epsilon = 1\n",
    "    random_reward = [0]\n",
    "\n",
    "    random_counter = 0\n",
    "    policy_counter = 0\n",
    "\n",
    "#     track_key1 = {'Sell': 0, 'Buy': 0, 'Hold': 0}\n",
    "#     track_key2 = {'Sell': 0, 'Buy': 0, 'Hold': 0}\n",
    "\n",
    "#     track_random_decision = {'Sell': 0, 'Buy': 0, 'Hold': 0}\n",
    "\n",
    "    reset_counter = 0\n",
    "\n",
    "    def __init__(self, dfEnv, iter_random_rounds, gamma, test_mode=False, cash=1000, share=0, pv=0):\n",
    "        super(macdChimpBot, self).__init__(dfEnv, iter_random_rounds, cash, share, pv)\n",
    "        # sets self.cash = 1000\n",
    "        # sets self.share = 0\n",
    "        # sets self.pv = 0\n",
    "        # sets self.pv_history_list = []\n",
    "        # sets self.env = dfEnv\n",
    "        # implements buy(self, stock_price)\n",
    "        # implements sell(self, stock_price)\n",
    "        # implements hold(self)\n",
    "        self.gamma = gamma\n",
    "        self.test_mode = test_mode\n",
    "        self.num_features = len(dfEnv.columns) - 1\n",
    "        self.random_rounds = iter_random_rounds # Number of rounds where the bot chooses to go monkey\n",
    "        \n",
    "        self.iter_env = self.env.iterrows()\n",
    "        self.now_env_index, self.now_row = self.iter_env.next()\n",
    "\n",
    "        # self.now_yes_share = 0\n",
    "        self.now_action = ''\n",
    "        # self.now_q = 0\n",
    "\n",
    "        self.prev_cash = self.cash\n",
    "        self.prev_share = self.share\n",
    "        self.prev_pv = self.pv\n",
    "\n",
    "        self.q_df_columns = list(self.env.columns)\n",
    "        self.q_df_columns.pop()\n",
    "        self.q_df_columns.extend(['Action', 'Q Value'])\n",
    "        self.q_df = pd.DataFrame(columns=self.q_df_columns)\n",
    "        self.q_dict = defaultdict(lambda: (0, 0)) # element of q_dict is (state, act): (q_value, t)\n",
    "        self.q_dict_analysis = defaultdict(lambda: (0, 0))\n",
    "\n",
    "#         self.negative_reward = 0\n",
    "#         self.n_reward_hisotry = []\n",
    "#         self.net_reward = 0\n",
    "\n",
    "        self.reset_counter = 0\n",
    "\n",
    "        # Smartcab use only\n",
    "        # self.penalty = False\n",
    "        # self.num_step = 0 # Number of steps for each trial; get reset each time a new trial begins\n",
    "\n",
    "    def make_q_df(self):\n",
    "        result_dict = defaultdict(list)\n",
    "\n",
    "        for index, row in self.q_dict.iteritems():\n",
    "            for i in range(len(self.q_dict.keys()[0])):\n",
    "                column_name = 'col' + str(i + 1)\n",
    "                result_dict[column_name].append(index[i])\n",
    "            result_dict['Q'].append(self.q_dict[index][0])\n",
    "\n",
    "        self.q_df = pd.DataFrame(result_dict)\n",
    "        q_df_column_list = ['col' + str(x) for x in range(1, self.num_features + 1 + 1)]\n",
    "        q_df_column_list.append('Q')\n",
    "        # q_df_column_list = ['col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9', 'col10', 'col11', 'col12', 'col13', 'col14', 'col15', 'col16', 'col17', 'col18', 'col19', 'col20', 'col21', 'col22', 'col23', 'col24', 'col25', 'col26', 'col27', 'col28', 'col29', 'col30', 'col31', 'col32', 'col33', 'col34', 'col35', 'col36', 'col37', 'col38', 'col39', 'Q']\n",
    "        self.q_df = self.q_df[q_df_column_list]\n",
    "\n",
    "        def transfer_action(x):\n",
    "            if x == 'Buy':\n",
    "                return 1\n",
    "            elif x == 'Sell':\n",
    "                return 2\n",
    "            elif x == 'Hold':\n",
    "                return 0\n",
    "            else:\n",
    "                raise ValueError(\"Wrong action!\")\n",
    "\n",
    "        def str_float_int(x):\n",
    "            return int(float(x))\n",
    "\n",
    "        arr_int = np.vectorize(str_float_int)\n",
    "\n",
    "        self.q_df['col' + str(self.num_features + 1)] = self.q_df['col' + str(self.num_features + 1)].apply(transfer_action)\n",
    "        self.q_df.ix[:, :-1] = self.q_df.ix[:, :-1].apply(arr_int)\n",
    "\n",
    "    def split_q_df(self):\n",
    "        self.q_df_X = self.q_df.ix[:, :-1]\n",
    "        self.q_df_y = self.q_df.ix[:, -1]\n",
    "        # self.X_train, self.X_test, self.y_train, self.y_test = cross_validation.train_test_split(self.q_df_X, self.q_df_y, test_size=0.1, random_state=0)\n",
    "\n",
    "    def train_on_q_df(self):\n",
    "        reg = RandomForestRegressor(n_estimators=128, max_features='sqrt', n_jobs=-1, random_state=0)\n",
    "        self.q_reg = reg\n",
    "        self.q_reg = self.q_reg.fit(self.q_df_X, self.q_df_y)\n",
    "\n",
    "    def update_q_model(self):\n",
    "#         print(\"Updating Q model...\")\n",
    "        start_time = time.time()\n",
    "        self.make_q_df()\n",
    "        self.split_q_df()\n",
    "        self.train_on_q_df()\n",
    "#         print(\"Update took {} seconds\".format(time.time() - start_time))\n",
    "\n",
    "    def from_state_action_predict_q(self, state_action):\n",
    "        state_action = [state_action]\n",
    "\n",
    "        pred_q = self.q_reg.predict(state_action)\n",
    "\n",
    "        return pred_q\n",
    "\n",
    "    # def yes_share(self):\n",
    "    #     # Represent chimp asset in state_action\n",
    "    #     if self.share > 0:\n",
    "    #         return 1\n",
    "    #     else:\n",
    "    #         return 0\n",
    "\n",
    "    def max_q(self, now_row):\n",
    "        def transfer_action(x):\n",
    "            if x == 'Buy':\n",
    "                return 1\n",
    "            elif x == 'Sell':\n",
    "                return 2\n",
    "            elif x == 'Hold':\n",
    "                return 0\n",
    "            else:\n",
    "                raise ValueError(\"Wrong action!\")\n",
    "\n",
    "        def str_float_int(x):\n",
    "            return int(float(x))\n",
    "\n",
    "        now_row2 = list(now_row)\n",
    "        # now_row2.append(self.now_yes_share)\n",
    "        max_q = ''\n",
    "        q_compare_dict = {}\n",
    "\n",
    "        if len(now_row2) > self.num_features:\n",
    "            raise ValueError(\"Got ya bastard! @ MaxQ\")\n",
    "\n",
    "        # Populate the q_dict\n",
    "        for act in set(self.valid_actions):\n",
    "            now_row2.append(act)\n",
    "            now_row_key = tuple(now_row2)\n",
    "\n",
    "            _ = self.q_dict[now_row_key]\n",
    "\n",
    "            # # K-Q Algorithm\n",
    "            # if np.random.choice(2, p = [0.9, 0.1]) == 1 and len(self.q_dict) > 30000:\n",
    "            # if _[1] == 0 and np.random.choice(2, p = [0.7, 0.3]) == 1 and len(self.q_dict) > 30000:\n",
    "            try:\n",
    "                self.q_reg\n",
    "            except AttributeError:\n",
    "                pass\n",
    "                # print('No q_reg yet...going with default.')\n",
    "            else:\n",
    "                if _[1] == 0:\n",
    "                    # print(\"Dreaming mode...\")\n",
    "                    # start_time = time.time()\n",
    "                    # self.update_q_model()\n",
    "\n",
    "                    single_X = np.array(now_row_key)\n",
    "                    # print(single_X)\n",
    "                    arr_int = np.vectorize(str_float_int)\n",
    "                    single_X[-1] = transfer_action(single_X[-1])\n",
    "                    single_X = arr_int(single_X)\n",
    "                    single_X = single_X.reshape(1, -1)\n",
    "                    pred_q = self.q_reg.predict(single_X)\n",
    "                    dreamed_q = (1 - (1 / (self.q_dict[now_row_key][1] + 1))) * self.q_dict[now_row_key][0] + (1 / (self.q_dict[now_row_key][1] + 1)) * pred_q[0]\n",
    "                    self.q_dict[now_row_key] = (dreamed_q, self.q_dict[now_row_key][1] + 1)\n",
    "                    # print(\"Q-dreamed: {0} for Act: {1}, taking {2} seconds.\".format(self.q_dict[now_row_key], act, time.time() - start_time))\n",
    "\n",
    "            # print(act, self.q_dict[now_row_key])\n",
    "\n",
    "            q_compare_dict[now_row_key] = self.q_dict[now_row_key]\n",
    "            now_row2.pop()\n",
    "\n",
    "        try:\n",
    "            max(q_compare_dict.iteritems(), key=lambda x:x[1])\n",
    "        except ValueError:\n",
    "            print(\"Wrong Q Value in Q Compare Dict!\")\n",
    "        else:\n",
    "            key, qAndT = max(q_compare_dict.iteritems(), key=lambda x:x[1])\n",
    "            # print(\"Action: {0}, with Q-value: {1}\".format(key[-1], qAndT[0]))\n",
    "            return key[-1], qAndT[0], qAndT[1]\n",
    "\n",
    "    def q_update(self):\n",
    "        # print(\"Data Index: {}\".format(self.now_env_index))\n",
    "        now_states = list(self.now_row)\n",
    "        # now_states = list(now_states)\n",
    "        now_states.pop() # disregard the Trade Price\n",
    "\n",
    "        prev_states = list(self.prev_states)\n",
    "\n",
    "        if len(prev_states) > self.num_features:\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update...something wrong with the self.prev_states!!!\")\n",
    "\n",
    "        # prev_states.append(self.prev_yes_share)\n",
    "        prev_states.append(self.prev_action)\n",
    "        prev_states_key = tuple(prev_states)\n",
    "\n",
    "        if len(prev_states_key) > self.num_features + 2:\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update\")\n",
    "\n",
    "        q_temp = self.q_dict[prev_states_key]\n",
    "\n",
    "        q_temp0 = (1 - (1 / (q_temp[1] + 1))) * q_temp[0] + (1 / (q_temp[1] + 1)) * (self.reward + self.gamma * self.max_q(now_states)[1])\n",
    "\n",
    "        if prev_states_key[:-1] == ('Low', 'Low', 'Average', 'Average', 'Low', 'Average', 'Average', 'Average', 'Low', 'Low', 'Low', 'Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'N-Very Low', 'Low', 'Average', 'N-Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'High', 'Yes'):\n",
    "            self.track_key1[prev_states_key[-1]] += 1\n",
    "        elif prev_states_key[:-1] == ('Low', 'Low', 'Average', 'Average', 'Low', 'Average', 'Average', 'Average', 'Low', 'Low', 'Low', 'Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'N-Very Low', 'Low', 'Average', 'N-Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'High', 'No'):\n",
    "            self.track_key2[prev_states_key[-1]] += 1\n",
    "        # elif prev_states_key[:-1] == ('Very High', 'Very High', 'Very High', 'Very High', 'Very High', 'Very High', 'Average', 'High', 'Average', 'Average', 'Average', 'Low', 'Average', 'Very Low', 'Low', 'N-Very Low', 'N-Very Low', 'N-Very Low', 'N-Very Low', 'Very Low', 'Very Low', 'Average', 'Very Low', 'Low', 'Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Low', 'Very Low', 'Low', 'Very Low', 'Average', 'No'):\n",
    "        #     self.track_key2[prev_states_key[-1]] += 1\n",
    "\n",
    "        self.q_dict[prev_states_key] = (q_temp0, q_temp[1] + 1)\n",
    "        # For analysis purpose\n",
    "        self.q_dict_analysis[prev_states_key] = (q_temp0, self.prev_env_index)\n",
    "        # print(\"Now Action: {}\".format())\n",
    "        # print(prev_states_key)\n",
    "        return (self.q_dict[prev_states_key])\n",
    "\n",
    "    def policy(self, now_row):\n",
    "        return self.max_q(now_row)[0]\n",
    "\n",
    "    def reset(self):\n",
    "        # Portfolio change over iterations\n",
    "        self.asset_history_list.append(self.pv + self.cash)\n",
    "\n",
    "        self.iter_env = self.env.iterrows()\n",
    "        self.now_env_index, self.now_row = self.iter_env.next()\n",
    "\n",
    "        self.cash = 1000\n",
    "        self.share = 0\n",
    "        self.pv = 0\n",
    "\n",
    "        self.prev_cash = self.cash\n",
    "        self.prev_share = self.share\n",
    "        self.prev_pv = self.pv\n",
    "\n",
    "        if self.test_mode is True:\n",
    "            self.epsilon = 0\n",
    "        \n",
    "        else:\n",
    "            if self.epsilon - 1/self.random_rounds > 0.00001: # Epislon threshold: 0.01\n",
    "                self.random_counter += 1\n",
    "                self.epsilon = self.epsilon - 1/self.random_rounds\n",
    "            else:\n",
    "                self.epsilon = 0.00001 # Epislon threshold: 0.1\n",
    "                self.policy_counter += 1\n",
    "\n",
    "        self.reset_counter += 1\n",
    "\n",
    "        if self.reset_counter % self.random_rounds == 0:\n",
    "            self.update_q_model()\n",
    "\n",
    "        if np.abs(self.epsilon - 0.00001) > 0.000001:\n",
    "            self.action_list = []\n",
    "        \n",
    "        # self.num_step = 0 # Recalculate the steps for the new trial\n",
    "        # self.penalty = False\n",
    "        # self.fail = False\n",
    "\n",
    "    def make_decision(self, now_row):\n",
    "        return self.policy(now_row)\n",
    "\n",
    "    def update(self, cost):\n",
    "        # Update state\n",
    "        now_states = list(self.now_row)\n",
    "\n",
    "        if len(now_states) > self.num_features + 1:\n",
    "            print(len(now_states))\n",
    "            print(self.num_features)\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update...something wrong with the self.now_row!!!\")\n",
    "\n",
    "        # now_states = list(now_states)\n",
    "        # print(type(self.now_row))\n",
    "        now_states.pop() # disregard the Trade Price\n",
    "\n",
    "        if len(now_states) > self.num_features:\n",
    "            print(now_states)\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update...something wrong with now_states after pop!!!\")\n",
    "\n",
    "        # Exploitation-exploration decisioning\n",
    "        random.seed(datetime.now())\n",
    "        self.decision = np.random.choice(2, p = [self.epsilon, 1 - self.epsilon]) # decide to go random or with the policy\n",
    "        # self.decision = 0 # Force random mode\n",
    "\n",
    "        # print(\"Random decision: {0}, Epislon: {1}\".format(self.decision, self.epsilon))\n",
    "        # print(\"What the FUCK?!\")\n",
    "        if self.decision == 0: # if zero, go random\n",
    "            random.seed(datetime.now())\n",
    "            action = random.choice(self.valid_actions)\n",
    "            # if tuple(now_states) == ('Low', 'Low', 'Average', 'Average', 'Low', 'Average', 'Average', 'Average', 'Low', 'Low', 'Low', 'Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'N-Very Low', 'Low', 'Average', 'N-Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'High'):\n",
    "            #     self.track_random_decision[action] += 1\n",
    "        else: # else go with the policy\n",
    "            # print(\"now_states: {}\".format(now_states))\n",
    "            # self.now_yes_share = self.yes_share()\n",
    "            action = self.make_decision(now_states)\n",
    "\n",
    "        if len(now_states) > self.num_features:\n",
    "            print(now_states)\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update...something wrong with now_states after make_decision!!!\")\n",
    "\n",
    "        # print(\"Now Action Real: {}\".format(action))\n",
    "        # Execute action and get reward\n",
    "        if action == 'Buy':\n",
    "            # print(self.now_row)\n",
    "            self.buy(self.now_row[-1], cost)\n",
    "        elif action == 'Sell':\n",
    "            # print(self.now_row)\n",
    "            self.sell(self.now_row[-1], cost)\n",
    "        elif action == 'Hold':\n",
    "            # print(self.now_row)\n",
    "            self.hold(self.now_row[-1])\n",
    "        else:\n",
    "            raise ValueError(\"Wrong action man!\")\n",
    "\n",
    "        try:\n",
    "            self.prev_states\n",
    "        except AttributeError:\n",
    "            print(\"Running the first time...no prevs exist.\")\n",
    "        else:\n",
    "            self.reward = ((self.cash - self.prev_cash) + (self.pv - self.prev_pv)) / (self.prev_cash + self.prev_pv)\n",
    "            self.q_update()\n",
    "\n",
    "        self.prev_states = now_states\n",
    "\n",
    "        if len(now_states) > self.num_features:\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update...something wrong with the now_states!!!\")\n",
    "\n",
    "        self.now_action = action\n",
    "        self.prev_action = action\n",
    "        # self.prev_yes_share = self.now_yes_share\n",
    "        self.prev_env_index = deepcopy(self.now_env_index)\n",
    "        self.prev_cash = self.cash\n",
    "        self.prev_share = self.share\n",
    "        self.prev_pv = self.pv\n",
    "\n",
    "        # if len(self.q_dict) > 20000:\n",
    "        #     self.update_q_model()\n",
    "\n",
    "        try:\n",
    "            self.now_env_index, self.now_row = self.iter_env.next()\n",
    "        except StopIteration:\n",
    "            pass\n",
    "            # print(\"End of data.\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # if reward < 0:\n",
    "        #     self.penalty = True\n",
    "\n",
    "        try:\n",
    "            _ = self.reward\n",
    "        except AttributeError:\n",
    "            print(\"No reward yet...0 assigned.\")\n",
    "            self.reward = 0\n",
    "        # print \"ChimpBot.update(): Action: {0} at Price: {1}, Cash: {2}, Num_Share: {3}, Cash + PV = {4}, Reward = {5}\".format(action, self.now_row[-1], self.cash, self.share, self.cash + self.pv, self.reward)  # [debug]\n",
    "        # print('Portfolio + Cash: {}'.format(self.cash + self.pv))\n",
    "        # print(\"================================\")\n",
    "    \n",
    "    def simulate(self, cost=None):\n",
    "        start_time = time.time()\n",
    "\n",
    "        for i in range(self.random_rounds):\n",
    "            for l in range(len(self.env)):\n",
    "                self.update(cost)\n",
    "            self.reset()\n",
    "        print(\"{0} rounds of simulation with cost = {1}, took {2} seconds\".format(self.random_rounds, cost, time.time() - start_time))\n",
    "        return self.asset_history_list, self.action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jpm_full = pd.DataFrame.from_csv('jpm_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the first time...no prevs exist.\n",
      "No reward yet...0 assigned.\n",
      "60000 rounds of simulation with cost = high, took 132291.043876 seconds\n",
      "count     8256\n",
      "unique       3\n",
      "top       Hold\n",
      "freq      4367\n",
      "dtype: object\n",
      "3.11803080497e+29\n"
     ]
    }
   ],
   "source": [
    "god_chimp = macdChimpBot(dfEnv=jpm_full, iter_random_rounds=60000, gamma=0.75)\n",
    "asset_history_list, action_list = god_chimp.simulate(cost='high')\n",
    "\n",
    "print(pd.Series(action_list).describe())\n",
    "print(asset_history_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_cost_action = action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('high_cost_action_60k_0.75.pickle', 'wb') as f:\n",
    "  pickle.dump(high_cost_action, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the first time...no prevs exist.\n",
      "No reward yet...0 assigned.\n",
      "60000 rounds of simulation with cost = high, took 118010.766502 seconds\n",
      "count     8256\n",
      "unique       3\n",
      "top       Hold\n",
      "freq      4414\n",
      "dtype: object\n",
      "2.06544060819e+29\n"
     ]
    }
   ],
   "source": [
    "god_chimp09 = macdChimpBot(dfEnv=jpm_full, iter_random_rounds=60000, gamma=0.9)\n",
    "asset_history_list, action_list = god_chimp09.simulate(cost='high')\n",
    "\n",
    "print(pd.Series(action_list).describe())\n",
    "print(asset_history_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
