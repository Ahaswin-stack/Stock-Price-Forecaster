{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-dd114a2d5465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfMain2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# dfMain = dfMain.join(dfSPY)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdfMain2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfJPM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dates' is not defined"
     ]
    }
   ],
   "source": [
    "dfMain2 = pd.DataFrame(index=dates)\n",
    "# dfMain = dfMain.join(dfSPY)\n",
    "dfMain2 = dfMain2.join(dfJPM)\n",
    "dfMain2.dropna(inplace=True)\n",
    "\n",
    "print(\"Inspect missing values:\")\n",
    "display(dfMain2.isnull().sum())\n",
    "print(len(dfMain2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfMain2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-ab90611dd45a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Adjust Open, High, Low, Volume\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Factor'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Factor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'High'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'High'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Factor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfMain2' is not defined"
     ]
    }
   ],
   "source": [
    "# Adjust Open, High, Low, Volume\n",
    "dfMain2['Adj Factor'] = dfMain2['Adj Close'] / dfMain2['Close']\n",
    "\n",
    "dfMain2['Open'] = dfMain2['Open'] * dfMain2['Adj Factor']\n",
    "dfMain2['High'] = dfMain2['High'] * dfMain2['Adj Factor']\n",
    "dfMain2['Low'] = dfMain2['Low'] * dfMain2['Adj Factor']\n",
    "\n",
    "dfMain2['Volume'] = dfMain2['Volume'] / dfMain2['Adj Factor']\n",
    "dfMain2.drop(['Close', 'Adj Factor'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfMain2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-92f840fc1c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfMain2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dfMain2' is not defined"
     ]
    }
   ],
   "source": [
    "display(dfMain2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfMain2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-39507b3d1853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Get opens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_Open'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Get adjCloses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_adjClose'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfMain2' is not defined"
     ]
    }
   ],
   "source": [
    "feature_days = 21 * 6\n",
    "\n",
    "# Price Engineering\n",
    "for i in range(feature_days):\n",
    "    # Get opens\n",
    "    dfMain2['-' + str(i + 1) + 'd_Open'] = dfMain2['Open'].shift(i + 1)\n",
    "    # Get adjCloses\n",
    "    dfMain2['-' + str(i + 1) + 'd_adjClose'] = dfMain2['Adj Close'].shift(i + 1)\n",
    "    # Get Highs\n",
    "    dfMain2['-' + str(i + 1) + 'd_High'] = dfMain2['High'].shift(i + 1)\n",
    "    # Get Lows\n",
    "    dfMain2['-' + str(i + 1) + 'd_Low'] = dfMain2['Low'].shift(i + 1)\n",
    "\n",
    "# TODO: remove -xd_Open, -xd_adjClose, -xd_High, -xd_Low, x = range(1, feature_days + 1)\n",
    "    \n",
    "period_list = [21*x for x in range(1, 13)] # Create relative bases\n",
    "period_list.extend([5, 10]) # Add 1, 2 week comparison basese\n",
    "print(period_list)\n",
    "\n",
    "for x in period_list:\n",
    "    # Get Max volumes\n",
    "    dfMain2[str(x) + 'd_Max_Vol'] = dfMain2['Volume'].rolling(window=x).max()\n",
    "    # Get Avg volumes\n",
    "    dfMain2[str(x) + 'd_Avg_Vol'] = dfMain2['Volume'].ewm(span=x).mean()\n",
    "    # Get Min volumes\n",
    "    dfMain2[str(x) + 'd_Min_Vol'] = dfMain2['Volume'].rolling(window=x).min()\n",
    "\n",
    "# TODO: remove xd_Max_Vol, xd_Avg_Vol, xd_Min_Vol, for x in period_list\n",
    "\n",
    "dfMain2['Abs_Spread'] = np.abs(dfMain2['Adj Close'] - dfMain2['Open'])\n",
    "# dfMain2['Abs_Spread_Shift1'] = dfMain2['Abs_Spread'].shift()\n",
    "\n",
    "for x in period_list:\n",
    "    # Get Max spreads\n",
    "    dfMain2[str(x) + 'd_Max_Spread'] = dfMain2['Abs_Spread'].rolling(window=x).max()\n",
    "    # Get Avg spreads\n",
    "    dfMain2[str(x) + 'd_Avg_Spread'] = dfMain2['Abs_Spread'].ewm(span=x).mean()\n",
    "\n",
    "# TODO: remove xd_Max_Spread, xd_Avg_Spread, for x in period_list\n",
    "\n",
    "dfMain2.drop(['Abs_Spread'], axis=1, inplace=True)\n",
    "\n",
    "display(dfMain2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfMain2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-9b953dc989f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Get volumes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_Vol'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Get relative volumes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mperiod_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfMain2' is not defined"
     ]
    }
   ],
   "source": [
    "# Volume Engineering\n",
    "start_time = time.time()\n",
    "for i in range(feature_days):\n",
    "    # Get volumes\n",
    "    dfMain2['-' + str(i + 1) + 'd_Vol'] = dfMain2['Volume'].shift(i + 1)\n",
    "    # Get relative volumes\n",
    "    for x in period_list:\n",
    "        dfMain2['-' + str(i + 1) + 'd_Vol_' + str(x) + 'Max'] = dfMain2['-' + str(i + 1) + 'd_Vol'] / dfMain2[str(x) + 'd_Max_Vol']\n",
    "        dfMain2['-' + str(i + 1) + 'd_Vol_' + str(x) + 'Avg'] = dfMain2['-' + str(i + 1) + 'd_Vol'] / dfMain2[str(x) + 'd_Avg_Vol']\n",
    "        dfMain2['-' + str(i + 1) + 'd_Vol_' + str(x) + 'Min'] = dfMain2['-' + str(i + 1) + 'd_Vol'] / dfMain2[str(x) + 'd_Min_Vol']\n",
    "        \n",
    "print(\"Generating volume features took {} seconds.\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfMain2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-777e58571021>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Get spread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_Spread'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_adjClose'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_Open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Get relative spread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mperiod_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfMain2' is not defined"
     ]
    }
   ],
   "source": [
    "# Spread Engineering\n",
    "start_time = time.time()\n",
    "for i in range(feature_days):\n",
    "    # Get spread\n",
    "    dfMain2['-' + str(i + 1) + 'd_Spread'] = dfMain2['-' + str(i + 1) + 'd_adjClose'] - dfMain2['-' + str(i + 1) + 'd_Open']\n",
    "    # Get relative spread\n",
    "    for x in period_list:\n",
    "        dfMain2['-' + str(i + 1) + 'd_Spread_' + str(x) + 'Max'] = dfMain2['-' + str(i + 1) + 'd_Spread'] / dfMain2[str(x) + 'd_Max_Spread']\n",
    "        dfMain2['-' + str(i + 1) + 'd_Spread_' + str(x) + 'Vol'] = dfMain2['-' + str(i + 1) + 'd_Spread'] / dfMain2[str(x) + 'd_Avg_Spread']\n",
    "#         dfMain2['-' + str(i + 1) + 'd_Spread_' + str(x) + 'Min'] = dfMain2['-' + str(i + 1) + 'd_Spread'] / dfMain2[str(x) + 'd_Min_Spread']\n",
    "\n",
    "print(\"Generating spread features took {} seconds.\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'period_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-8328b3c6b7c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Level Engineering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mperiod_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Get Max adjClose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_Max_Price'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'period_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Level Engineering\n",
    "start_time = time.time()\n",
    "for x in period_list:\n",
    "    # Get Max adjClose\n",
    "    dfMain2[str(x) + 'd_Max_Price'] = dfMain2['Adj Close'].rolling(window=x).max()\n",
    "    # Get Avg adjClose\n",
    "    dfMain2[str(x) + 'd_Avg_Price'] = dfMain2['Adj Close'].ewm(span=x).mean()\n",
    "    # Get Min adjClose\n",
    "    dfMain2[str(x) + 'd_Min_Price'] = dfMain2['Adj Close'].rolling(window=x).min()\n",
    "    # Get Std adjClose\n",
    "    dfMain2[str(x) + 'd_Std_Price'] = dfMain2['Adj Close'].ewm(span=x).std()\n",
    "\n",
    "# TODO: remove xd_Max_Price, xd_Avg_Price, xd_Min_Price. Retain xd_Std_Price for x in period_list\n",
    "\n",
    "for i in range(feature_days):\n",
    "    # Get relative price\n",
    "    for x in period_list:\n",
    "        dfMain2['-' + str(i + 1) + 'd_Price_' + str(x) + 'Max'] = dfMain2['-' + str(i + 1) + 'd_adjClose'] / dfMain2[str(x) + 'd_Max_Price']\n",
    "        dfMain2['-' + str(i + 1) + 'd_Price_' + str(x) + 'Vol'] = dfMain2['-' + str(i + 1) + 'd_adjClose'] / dfMain2[str(x) + 'd_Avg_Price']\n",
    "        dfMain2['-' + str(i + 1) + 'd_Price_' + str(x) + 'Min'] = dfMain2['-' + str(i + 1) + 'd_adjClose'] / dfMain2[str(x) + 'd_Min_Price']\n",
    "        \n",
    "print(\"Generating level features took {} seconds.\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfMain2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-50f095cb486c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdfMain2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_upperwick_bool'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupperwick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_Open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_adjClose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_High'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mdfMain2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_lowerwick_bool'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlowerwick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_Open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_adjClose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_Low'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfMain2' is not defined"
     ]
    }
   ],
   "source": [
    "def upperwick(open, adj_close, high):\n",
    "    if high > open and high > adj_close:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def lowerwick(open, adj_close, low):\n",
    "    if low < open and low < adj_close:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# Get wicks - new code has 10X speed!\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(feature_days):\n",
    "    dfMain2.ix[:, '-' + str(i + 1) + 'd_upperwick_bool'] = dfMain2.apply(lambda row: upperwick(row['-' + str(i + 1) + 'd_Open'], row['-' + str(i + 1) + 'd_adjClose'], row['-' + str(i + 1) + 'd_High']), axis=1)\n",
    "    dfMain2.ix[:, '-' + str(i + 1) + 'd_lowerwick_bool'] = dfMain2.apply(lambda row: lowerwick(row['-' + str(i + 1) + 'd_Open'], row['-' + str(i + 1) + 'd_adjClose'], row['-' + str(i + 1) + 'd_Low']), axis=1)        \n",
    "\n",
    "# TODO: remove -xd_upperwick_bool, -xd_lowerwick_bool, x in range(1, feature_days + 1)\n",
    "print(\"Getting wicks took {} seconds.\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfMain2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-15eac6f64008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Transform upper wicks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mhas_upperwicks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_upperwick_bool'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mhas_lowerwicks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd_lowerwick_bool'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfMain2' is not defined"
     ]
    }
   ],
   "source": [
    "def get_upperwick_length(open, adj_close, high):\n",
    "    return high - max(open, adj_close)\n",
    "\n",
    "def get_lowerwick_length(open, adj_close, low):\n",
    "    return min(open, adj_close) - low\n",
    "    \n",
    "    \n",
    "start_time = time.time()\n",
    "\n",
    "# Transform upper wicks\n",
    "for i in range(feature_days):\n",
    "    has_upperwicks = dfMain2['-' + str(i + 1) + 'd_upperwick_bool']\n",
    "    has_lowerwicks = dfMain2['-' + str(i + 1) + 'd_lowerwick_bool']\n",
    "    \n",
    "    dfMain2.loc[has_upperwicks, '-' + str(i + 1) + 'd_upperwick'] = dfMain2.loc[has_upperwicks, :].apply(lambda row: get_upperwick_length(row['-' + str(i + 1) + 'd_Open'], row['-' + str(i + 1) + 'd_adjClose'], row['-' + str(i + 1) + 'd_High']), axis=1)\n",
    "    dfMain2.loc[has_lowerwicks, '-' + str(i + 1) + 'd_lowerwick'] = dfMain2.loc[has_lowerwicks, :].apply(lambda row: get_lowerwick_length(row['-' + str(i + 1) + 'd_Open'], row['-' + str(i + 1) + 'd_adjClose'], row['-' + str(i + 1) + 'd_Low']), axis=1)\n",
    "    \n",
    "    # Get relative upperwick length\n",
    "    dfMain2.loc[dfMain2['-' + str(i + 1) + 'd_upperwick_bool'], '-' + str(i + 1) + 'd_upperwick'] = dfMain2.loc[dfMain2['-' + str(i + 1) + 'd_upperwick_bool'], '-' + str(i + 1) + 'd_upperwick'] / dfMain2.loc[dfMain2['-' + str(i + 1) + 'd_upperwick_bool'], '126d_Avg_Spread']\n",
    "    # Get relative lowerwick length\n",
    "    dfMain2.loc[dfMain2['-' + str(i + 1) + 'd_lowerwick_bool'], '-' + str(i + 1) + 'd_lowerwick'] = dfMain2.loc[dfMain2['-' + str(i + 1) + 'd_lowerwick_bool'], '-' + str(i + 1) + 'd_lowerwick'] / dfMain2.loc[dfMain2['-' + str(i + 1) + 'd_lowerwick_bool'], '126d_Avg_Spread']\n",
    "\n",
    "    # Assign 0 to no-upperwick days\n",
    "    dfMain2.loc[np.logical_not(dfMain2['-' + str(i + 1) + 'd_upperwick_bool']), '-' + str(i + 1) + 'd_upperwick'] = 0\n",
    "    # Assign 0 to no-lowerwick days\n",
    "    dfMain2.loc[np.logical_not(dfMain2['-' + str(i + 1) + 'd_lowerwick_bool']), '-' + str(i + 1) + 'd_lowerwick'] = 0\n",
    "\n",
    "print(\"Transforming wicks took {} seconds.\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfMain2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-4fe6a387c865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trade Price'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfMain2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trade Price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfMain2' is not defined"
     ]
    }
   ],
   "source": [
    "dfMain2['Trade Price'] = dfMain2['Adj Close']\n",
    "print(dfMain2[['Trade Price', 'Open', 'Adj Close']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfMain2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-c539d9ce8f92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfMain2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dfMain2' is not defined"
     ]
    }
   ],
   "source": [
    "print(dfMain2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfMain2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-d6fc4ec92682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mdrop_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_list\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mraw_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvol_compare_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvol_meta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msprd_compare_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mspread_meta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprice_compare_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwick_bools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mdfMain2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dfMain2' is not defined"
     ]
    }
   ],
   "source": [
    "# Remove raw features\n",
    "# raw_features = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "raw_features = []\n",
    "\n",
    "# Remove vol comparison base\n",
    "# vol_compare_type = ['Max', 'Avg', 'Min']\n",
    "vol_compare_features = []\n",
    "\n",
    "# Remove vol meta features\n",
    "vol_meta = []\n",
    "# for d in range(1, feature_days + 1):\n",
    "#     vol_meta.append('-' + str(d) + 'd_Vol')\n",
    "\n",
    "# Remove spread comparison base\n",
    "# sprd_compare_type = ['Max', 'Avg']\n",
    "sprd_compare_features = []\n",
    "\n",
    "# for d in period_list:\n",
    "#     for t in vol_compare_type:\n",
    "#         vol_compare_features.append(str(d) + 'd_' + t + '_Vol')\n",
    "#     for u in sprd_compare_type:\n",
    "#         sprd_compare_features.append(str(d) + 'd_' + u + '_Spread')\n",
    "\n",
    "# Remove spread meta features\n",
    "# price_raw = ['Open', 'adjClose', 'High', 'Low']\n",
    "spread_meta = []\n",
    "\n",
    "# for d in range(1, feature_days + 1):\n",
    "#     for t in price_raw:\n",
    "#         spread_meta.append('-' + str(d) + 'd_' + t)\n",
    "\n",
    "# Remove price comparison base\n",
    "# price_compare_type = vol_compare_type\n",
    "price_compare_features = []\n",
    "\n",
    "# for d in period_list:\n",
    "#     for t in price_compare_type:\n",
    "#         price_compare_features.append(str(d) + 'd_' + t + '_Price')\n",
    "\n",
    "# Remove wick bools\n",
    "wick_type = ['upperwick', 'lowerwick']\n",
    "wick_bools = []\n",
    "\n",
    "for d in range(1, feature_days + 1):\n",
    "    for t in wick_type:\n",
    "        wick_bools.append('-' + str(d) + 'd_' + t + '_bool')\n",
    "\n",
    "drop_list = []\n",
    "drop_list = drop_list + raw_features + vol_compare_features + vol_meta + sprd_compare_features + spread_meta + price_compare_features + wick_bools\n",
    "\n",
    "dfMain2.drop(drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfMain2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-6e2905e2a20c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_data_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfMain2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnew_data_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfMain2' is not defined"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "new_data_full = deepcopy(dfMain2)\n",
    "new_data_full.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-4de37fbf34a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data_full' is not defined"
     ]
    }
   ],
   "source": [
    "display(new_data_full.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-232a43cd8b37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add derivatives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Add 1st derivatives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdiff1_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnew_data_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdiff1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff1_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_diff1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data_full' is not defined"
     ]
    }
   ],
   "source": [
    "# Add derivatives\n",
    "# Add 1st derivatives\n",
    "diff1_temp = new_data_full.ix[:, :-1] - new_data_full.ix[:, :-1].shift()\n",
    "diff1 = diff1_temp.add_suffix('_diff1')\n",
    "\n",
    "# Add 2nd derivatives\n",
    "diff2 = diff1_temp - diff1_temp.shift()\n",
    "diff2 = diff2.add_suffix('_diff2')\n",
    "\n",
    "# Concatenate all dataframes\n",
    "trade_price = new_data_full['Trade Price']\n",
    "new_data_full = pd.concat([new_data_full, diff1, diff2], axis=1)\n",
    "new_data_full['Trade Price'] = trade_price\n",
    "new_data_full.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-74fadd79cf12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrade_price_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trade Price\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrade_price_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrade_price_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrade_price_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew_data_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data_full' is not defined"
     ]
    }
   ],
   "source": [
    "trade_price_idx = new_data_full.columns.get_loc(\"Trade Price\")\n",
    "cols = new_data_full.columns.tolist()\n",
    "cols = cols[:trade_price_idx] + cols[trade_price_idx + 1:] + [cols[trade_price_idx]]\n",
    "new_data_full = new_data_full.reindex(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-df1f9353fea5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data_full' is not defined"
     ]
    }
   ],
   "source": [
    "def split_data(df):\n",
    "    df_features = df.ix[:, :-1]\n",
    "    df_labels = df.ix[:, -1]\n",
    "    return df_features, df_labels\n",
    "\n",
    "df_features, df_labels = split_data(new_data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-c6d6122e6287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_test_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_features_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "def normalization(X_train, X_test):\n",
    "    X_test_norm = (X_test - X_train.mean()) / (X_train.max() - X_train.min())\n",
    "    return X_test_norm\n",
    "\n",
    "df_features_norm = normalization(df_features, df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_features_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-b6a4e67bcecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpca_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpca_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_features_norm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# all data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcp_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_features_norm' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Choose n in PCA\n",
    "pca_dim = 1000\n",
    "pca = PCA(n_components=pca_dim)\n",
    "pca.fit(df_features_norm) # all data\n",
    "\n",
    "cp_imp = pca.explained_variance_ratio_\n",
    "cp_imp = pd.Series(cp_imp)\n",
    "cp_imp_cum = cp_imp.cumsum()\n",
    "cp_imp_cum.plot()\n",
    "\n",
    "print(\"Running PCA took {} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_features_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-71775ba60806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_pca\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf_features_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_transform_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_features_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_features_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_features_norm' is not defined"
     ]
    }
   ],
   "source": [
    "# PCA Fit and Transformation and DF Reconstruction\n",
    "def pca_transform_reconstruct(fit_data, trans_data, pca_dim):            \n",
    "    pca = PCA(n_components=pca_dim)\n",
    "    pca.fit(fit_data)\n",
    "\n",
    "    data_pca = pca.transform(trans_data)\n",
    "    data_pca = pd.DataFrame(data=data_pca)\n",
    "    data_pca['Date'] = trans_data.index\n",
    "    data_pca.set_index(data_pca['Date'], inplace=True)\n",
    "    del data_pca.index.name\n",
    "    del data_pca['Date']\n",
    "    \n",
    "    return data_pca\n",
    "\n",
    "df_features_pca = pca_transform_reconstruct(df_features_norm, df_features_norm, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_features_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-57a2ffee6bfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_features_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_features_pca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_features_pca' is not defined"
     ]
    }
   ],
   "source": [
    "df_features = normalization(df_features_pca, df_features_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-078e969d2445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_data_full_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnew_data_full_pca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trade Price'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_features' is not defined"
     ]
    }
   ],
   "source": [
    "new_data_full_pca = df_features\n",
    "new_data_full_pca['Trade Price'] = df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation phase\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_data_full_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-aa0cc33e4d4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation phase\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} Trade Price: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_start_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data_full_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_start_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Trade Price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} Trade Price: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_end_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data_full_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_end_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Trade Price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mvalidation_phase_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data_full_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_start_date\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvalidation_end_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data_full_pca' is not defined"
     ]
    }
   ],
   "source": [
    "validation_start_date = datetime(2006, 9, 25)\n",
    "validation_end_date = datetime(2011, 9, 27)\n",
    "test_start_date = datetime(2011, 9, 26)\n",
    "test_end_date = datetime(2016, 9, 27)\n",
    "\n",
    "print(\"Validation phase\")\n",
    "print(\"{0} Trade Price: {1}\".format(validation_start_date, new_data_full_pca.ix[validation_start_date, 'Trade Price']))\n",
    "print(\"{0} Trade Price: {1}\".format(validation_end_date, new_data_full_pca.ix[validation_end_date, 'Trade Price']))\n",
    "validation_phase_data = new_data_full_pca.ix[validation_start_date:validation_end_date, :]\n",
    "print(\"Number of dates in validation dataset: {}\\n\".format(len(validation_phase_data)))\n",
    "\n",
    "print(\"Test phase\")\n",
    "print(\"{0} Trade Price: {1}\".format(test_start_date, new_data_full_pca.ix[test_start_date, 'Trade Price']))\n",
    "print(\"{0} Trade Price: {1}\".format(test_end_date, new_data_full_pca.ix[test_end_date, 'Trade Price']))\n",
    "test_phase_data = new_data_full_pca.ix[test_start_date:test_end_date, :]\n",
    "print(\"Number of dates in test dataset: {}\".format(len(test_phase_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MonkeyBot(object):\n",
    "    def __init__(self, dfEnv, cash=1000, share=0, pv=0, random_state=0):\n",
    "        random.seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        self.cash = cash\n",
    "        self.share = share\n",
    "        self.pv = pv\n",
    "        self.asset_history_list = []\n",
    "        self.action_list = []\n",
    "        \n",
    "        self.env = deepcopy(dfEnv)\n",
    "\n",
    "    def buy(self, stock_price, cost, fold=1):\n",
    "        if self.cash < stock_price:\n",
    "            self.hold(stock_price)\n",
    "            \n",
    "        else:\n",
    "            num_affordable = int(self.cash // stock_price)\n",
    "            buy_amount = int(num_affordable // fold)\n",
    "            self.cash = self.cash - stock_price * buy_amount\n",
    "            self.share = self.share + buy_amount\n",
    "            self.pv = stock_price * self.share\n",
    "\n",
    "             # Adding transaction cost\n",
    "            self.trading_cost(buy_amount, cost)\n",
    "            \n",
    "        # Append action to action list\n",
    "        self.action_list.append('Buy')\n",
    "\n",
    "    def sell(self, stock_price, cost, fold=1):\n",
    "        if self.share == 0:\n",
    "            self.hold(stock_price)\n",
    "            \n",
    "        else:\n",
    "            sell_amount = int(self.share // fold)\n",
    "            self.cash = self.cash + stock_price * sell_amount\n",
    "            self.pv = 0\n",
    "            self.share = 0\n",
    "\n",
    "            # Adding transaction cost\n",
    "            self.trading_cost(sell_amount, cost)\n",
    "            \n",
    "        self.action_list.append('Sell')\n",
    "\n",
    "    def hold(self, stock_price):\n",
    "        self.pv = stock_price * self.share\n",
    "\n",
    "    def trading_cost(self, trading_amount, cost):\n",
    "            if cost is None:\n",
    "                pass                \n",
    "            elif cost == 'low':\n",
    "                if trading_amount * 0.01 < 1.99:\n",
    "                    self.cash = self.cash - 1.99\n",
    "                else:\n",
    "                    self.cash = self.cash - trading_amount * 0.01\n",
    "            elif cost == 'medium':\n",
    "                if trading_amount * 0.01 < 5:\n",
    "                    self.cash = self.cash - 5\n",
    "                else:\n",
    "                    self.cash = self.cash - trading_amount * 0.01\n",
    "            elif cost == 'high':\n",
    "                if trading_amount * 0.01 < 7:\n",
    "                    self.cash = self.cash - 7\n",
    "                else:\n",
    "                    self.cash = self.cash - trading_amount * 0.01\n",
    "            else:\n",
    "                raise ValueError(\"Invalid cost parameter!\")\n",
    "        \n",
    "    def reset(self):\n",
    "        self.cash = 1000\n",
    "        self.share = 0\n",
    "        self.pv = 0\n",
    "\n",
    "    def make_decision(self, x, cost):\n",
    "        random_choice = random.choice([1, 2])\n",
    "\n",
    "        if random_choice == 0:\n",
    "            self.hold(x)\n",
    "        elif random_choice == 1:\n",
    "            self.buy(x, cost)\n",
    "        elif random_choice == 2:\n",
    "            self.sell(x, cost)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid choice!\")\n",
    "\n",
    "        return self.pv # for frame-wise operation\n",
    "\n",
    "    def simulate(self, iters, cost=None):\n",
    "        start_time = time.time()\n",
    "        for i in range(iters):\n",
    "            for index, row in self.env.iterrows():\n",
    "                self.make_decision(row['Trade Price'], cost)\n",
    "            self.asset_history_list.append(self.pv + self.cash)\n",
    "            self.reset()\n",
    "        print(\"{0} iterations took {1} seconds\".format(iters, time.time() - start_time))\n",
    "        \n",
    "        return self.asset_history_list, self.action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'monkey_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-1020589dd8a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonkey_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_history_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'monkey_full' is not defined"
     ]
    }
   ],
   "source": [
    "pd.Series(monkey_full.asset_history_list).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "class ChimpBot(MonkeyBot):\n",
    "    \"\"\"An agent that learns to drive in the smartcab world.\"\"\"\n",
    "    \n",
    "    def __init__(self, dfEnv, iter_random_rounds, gamma, random_state=0, test_mode=False, cash=1000, share=0, pv=0):\n",
    "        super(ChimpBot, self).__init__(dfEnv, iter_random_rounds, cash, share, pv)\n",
    "        # From MonkeyBot:\n",
    "        # sets self.cash = 1000\n",
    "        # sets self.share = 0\n",
    "        # sets self.pv = 0\n",
    "        # sets self.pv_history_list = []\n",
    "        # sets self.env = dfEnv\n",
    "        # implements buy(self, stock_price)\n",
    "        # implements sell(self, stock_price)\n",
    "        # implements hold(self)\n",
    "\n",
    "        # Set random state\n",
    "        self.random_state = random_state\n",
    "        random.seed(self.random_state)\n",
    "        np.random.seed(self.random_state)\n",
    "        \n",
    "        # Chimp parameters\n",
    "        self.valid_actions = ['Buy', 'Sell']\n",
    "        self.gamma = gamma # Discount factor\n",
    "        self.epsilon = 1 # Exploration-exploitation\n",
    "        self.test_mode = test_mode\n",
    "        self.random_rounds = iter_random_rounds # Number of rounds where the bot chooses to go monkey\n",
    "        self.num_features = len(dfEnv.columns) # Use every columns from the input data\n",
    "        \n",
    "        # Turn input data into index, row\n",
    "        self.iter_env = self.env.iterrows()\n",
    "        self.now_env_index, self.now_row = self.iter_env.next()\n",
    "\n",
    "        # Numpy alternative\n",
    "#         self.env_arr = self.env.values\n",
    "#         self.now_row = 0\n",
    "\n",
    "        # May need to put back later\n",
    "#         self.prev_cash = self.cash\n",
    "#         self.prev_share = self.share\n",
    "#         self.prev_pv = self.pv\n",
    "\n",
    "        # Q-table and q_df\n",
    "        self.q_df_columns = list(self.env.columns)\n",
    "        self.q_df_columns.extend(['Action', 'Q Value'])\n",
    "        self.q_df = pd.DataFrame(columns=self.q_df_columns)\n",
    "        \n",
    "        self.q_dict = defaultdict(lambda: (0, 0)) # element of q_dict is (state, act): (q_value, t)\n",
    "        self.q_dict_analysis = defaultdict(lambda: (0, 0))\n",
    "\n",
    "        # Misc\n",
    "        self.reset_counter = 0\n",
    "\n",
    "    def make_q_df(self):\n",
    "        \"\"\"Make a q_df out of the q_dict.\"\"\"\n",
    "        print(\"Making q_df...\")\n",
    "        result_dict = defaultdict(list)\n",
    "        for index, row in self.q_dict.iteritems():\n",
    "            for i in range(len(self.q_dict.keys()[0])):\n",
    "                column_name = 'col' + str(i + 1)\n",
    "                result_dict[column_name].append(index[i])\n",
    "            result_dict['Q'].append(self.q_dict[index][0])\n",
    "\n",
    "        self.q_df = pd.DataFrame(result_dict)\n",
    "        q_df_column_list = ['col' + str(x) for x in range(1, self.num_features - 1 + 1 + 1)] # features + action\n",
    "        q_df_column_list.append('Q')\n",
    "        self.q_df = self.q_df[q_df_column_list]\n",
    "\n",
    "        def transfer_action(x):\n",
    "            if x == 'Buy':\n",
    "                return 1\n",
    "            elif x == 'Sell':\n",
    "                return 2\n",
    "            elif x == 'Hold':\n",
    "                return 0\n",
    "            else:\n",
    "                raise ValueError(\"Wrong action!\")\n",
    "\n",
    "        def str_float_int(x):\n",
    "            return int(float(x))\n",
    "\n",
    "        arr_int = np.vectorize(str_float_int)\n",
    "\n",
    "        print(self.q_df.head())\n",
    "        self.q_df.ix[:, -2] = self.q_df.ix[:, -2].apply(transfer_action)\n",
    "        self.q_df.ix[:, :-1] = self.q_df.ix[:, :-1].apply(arr_int) # Maybe useless\n",
    "\n",
    "    def split_q_df(self):\n",
    "        \"\"\"Splitting q_df into features and labels.\"\"\"\n",
    "        \n",
    "        self.q_df_X = self.q_df.ix[:, :-1]\n",
    "        self.q_df_y = self.q_df.ix[:, -1]\n",
    "\n",
    "    def train_on_q_df(self):\n",
    "        \"\"\"Model the q_df.\"\"\"\n",
    "        print(\"Training on q_df...\")\n",
    "        self.q_reg = RandomForestRegressor(n_estimators=2000, max_features='sqrt', n_jobs=-1, random_state=self.random_state)\n",
    "        self.q_reg = self.q_reg.fit(self.q_df_X, self.q_df_y)\n",
    "\n",
    "    def update_q_model(self):\n",
    "        \"\"\"1. Make q_df\n",
    "           2. Split q_df\n",
    "           3. Train on q_df\n",
    "        \"\"\"\n",
    "#         print(\"Updating Q model...\")\n",
    "#         start_time = time.time()\n",
    "        self.make_q_df()\n",
    "        self.split_q_df()\n",
    "        self.train_on_q_df()\n",
    "#         print(\"Update took {} seconds\".format(time.time() - start_time))\n",
    "\n",
    "    def from_state_action_predict_q(self, state_action):\n",
    "        \"\"\"Make prediction using self.reg\"\"\"\n",
    "        state_action = [state_action]\n",
    "        pred_q = self.q_reg.predict(state_action)\n",
    "\n",
    "        return pred_q\n",
    "\n",
    "    def max_q(self):\n",
    "#         print(\"Calculating Max Q\")\n",
    "        def transfer_action(x):\n",
    "            if x == 'Buy':\n",
    "                return 1\n",
    "            elif x == 'Sell':\n",
    "                return 2\n",
    "            elif x == 'Hold':\n",
    "                return 0\n",
    "            else:\n",
    "                raise ValueError(\"Invalid action!\")\n",
    "\n",
    "#         def str_float_int(x):\n",
    "#             return int(float(x))\n",
    "\n",
    "        max_q = None\n",
    "        q_compare_dict = {}\n",
    "\n",
    "        if len(self.now_states) != self.num_features - 1:\n",
    "            raise ValueError(\"Got ya bastard! @ MaxQ\")\n",
    "\n",
    "        # Populate the q_dict\n",
    "        for act in set(self.valid_actions):\n",
    "            # added 1 more additional features to the feature set\n",
    "            self.now_states.append(act)\n",
    "            now_row_key = tuple(self.now_states)\n",
    "\n",
    "            _ = self.q_dict[now_row_key]\n",
    "\n",
    "            try:\n",
    "                self.q_reg\n",
    "            except AttributeError:\n",
    "                pass\n",
    "                # print('No q_reg yet...going with default.')\n",
    "            else:\n",
    "                if _[1] == 0:\n",
    "                    # print(\"Dreaming mode...\")                    \n",
    "                    single_X = np.array(now_row_key)\n",
    "                    # print(single_X)\n",
    "#                     arr_int = np.vectorize(str_float_int)\n",
    "                    single_X[-1] = transfer_action(single_X[-1])\n",
    "#                     single_X = arr_int(single_X)\n",
    "                    single_X = single_X.reshape(1, -1)\n",
    "                    pred_q = self.q_reg.predict(single_X)\n",
    "                    dreamed_q = (1 - (1 / (self.q_dict[now_row_key][1] + 1))) * self.q_dict[now_row_key][0] + (1 / (self.q_dict[now_row_key][1] + 1)) * pred_q[0]\n",
    "                    self.q_dict[now_row_key] = (dreamed_q, self.q_dict[now_row_key][1] + 1)\n",
    "\n",
    "            q_compare_dict[now_row_key] = self.q_dict[now_row_key]\n",
    "            self.now_states.pop()\n",
    "\n",
    "        try:\n",
    "            key, qAndT = max(q_compare_dict.iteritems(), key=lambda x:x[1])\n",
    "        except ValueError:\n",
    "            print(\"Wrong Q Value in Q Compare Dict!\")\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            return key[-1], qAndT[0], qAndT[1]\n",
    "\n",
    "    def q_update(self):\n",
    "#         print(\"Updating Q table...\")\n",
    "        # prev_states.append(self.prev_yes_share)\n",
    "        self.prev_states.append(self.prev_action)\n",
    "        prev_states_key = tuple(self.prev_states)\n",
    "\n",
    "        if len(prev_states_key) != self.num_features - 1 + 1:\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update\")\n",
    "\n",
    "        q_temp = self.q_dict[prev_states_key]\n",
    "        q_temp0 = (1 - (1 / (q_temp[1] + 1))) * q_temp[0] + (1 / (q_temp[1] + 1)) * (self.reward + self.gamma * self.max_q()[1])\n",
    "\n",
    "        self.q_dict[prev_states_key] = (q_temp0, q_temp[1] + 1)\n",
    "        # For analysis purpose\n",
    "        self.q_dict_analysis[prev_states_key] = (q_temp0, self.prev_env_index)\n",
    "\n",
    "    def reset(self):\n",
    "#         print(\"Resetting...\")\n",
    "        # Portfolio change over iterations\n",
    "        self.asset_history_list.append(self.pv + self.cash)\n",
    "\n",
    "        self.iter_env = self.env.iterrows()\n",
    "        self.now_env_index, self.now_row = self.iter_env.next()\n",
    "#         self.now_row = 0 # Numpy option\n",
    "\n",
    "        self.cash = 1000\n",
    "        self.share = 0\n",
    "        self.pv = 0\n",
    "\n",
    "        # Delete all prevs\n",
    "        del self.prev_states\n",
    "        del self.prev_env_index        \n",
    "        del self.prev_cash\n",
    "        del self.prev_share\n",
    "        del self.prev_pv\n",
    "        del self.prev_action\n",
    "\n",
    "        if self.test_mode is True:\n",
    "            self.epsilon = 0\n",
    "        \n",
    "        else:\n",
    "            if self.epsilon - 1/self.random_rounds > 0.00001: # Epislon threshold: 0.01\n",
    "                self.epsilon = self.epsilon - 1/self.random_rounds\n",
    "            else:\n",
    "                self.epsilon = 0.00001 # Epislon threshold: 0.1\n",
    "                \n",
    "        self.reset_counter += 1\n",
    "\n",
    "        if self.reset_counter % self.random_rounds == 0:\n",
    "            self.update_q_model()\n",
    "\n",
    "        if np.abs(self.epsilon - 0.00001) > 0.000001:\n",
    "            self.action_list = []\n",
    "\n",
    "    def make_decision(self):\n",
    "        return self.max_q()[0]\n",
    "\n",
    "    def update(self, cost):\n",
    "        # Update state\n",
    "        self.now_states = list(self.now_row)\n",
    "        self.now_states.pop() # Remove Trade Price\n",
    "\n",
    "### Numpy option\n",
    "#         try:\n",
    "#             self.now_states = list(self.env_arr[self.now_row])\n",
    "#         except IndexError:\n",
    "#             print(\"End of data.\")\n",
    "#             sys.exit(1)\n",
    "#         self.now_states.pop() # Remove Trade Price\n",
    "\n",
    "        if len(self.now_states) != self.num_features - 1:\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update...something wrong with the self.now_row!!!\")\n",
    "\n",
    "        # Update Q-table using prevs\n",
    "        try:\n",
    "            self.prev_states\n",
    "        except AttributeError:\n",
    "            pass\n",
    "#             print(\"Running the first time...no prevs exist.\")\n",
    "        else:\n",
    "            self.hold(self.now_row[-1])\n",
    "            self.reward = ((self.cash - self.prev_cash) + (self.pv - self.prev_pv)) / (self.prev_cash + self.prev_pv)\n",
    "            self.q_update()\n",
    "\n",
    "        # All the prev stuff!\n",
    "        self.prev_states = copy(self.now_states)\n",
    "        self.prev_env_index = deepcopy(self.now_env_index)\n",
    "#         self.prev_env_index = self.env.index[self.now_row] # Numpy option\n",
    "        self.prev_cash = self.cash\n",
    "        self.prev_share = self.share\n",
    "        self.prev_pv = self.pv\n",
    "        \n",
    "        # Exploitation-exploration decisioning\n",
    "        self.decision = np.random.choice(2, p = [self.epsilon, 1 - self.epsilon]) # decide to go random or with the policy\n",
    "        # self.decision = 0 # Force random mode\n",
    "\n",
    "        # print(\"Random decision: {0}, Epislon: {1}\".format(self.decision, self.epsilon))\n",
    "        if self.decision == 0: # if zero, go random\n",
    "            action = random.choice(self.valid_actions)\n",
    "        else: # else go with the policy\n",
    "            action = self.make_decision()\n",
    "\n",
    "        # Execute action and get reward\n",
    "        if action == 'Buy':\n",
    "            # print(self.now_row)\n",
    "            self.buy(self.now_row[-1], cost)\n",
    "#             self.buy(self.env_arr[self.now_row][-1], cost) # Numpy option\n",
    "        elif action == 'Sell':\n",
    "            # print(self.now_row)\n",
    "            self.sell(self.now_row[-1], cost)\n",
    "#             self.sell(self.env_arr[self.now_row][-1], cost) # Numpy option\n",
    "        elif action == 'Hold':\n",
    "            # print(self.now_row)\n",
    "            self.hold(self.now_row[-1])\n",
    "#             self.hold(self.env_arr[self.now_row][-1]) # Numpy option\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action man!\")\n",
    "        \n",
    "        self.prev_action = action\n",
    "        \n",
    "#         self.now_row += 1 # Numpy option\n",
    "\n",
    "        try:\n",
    "            self.now_env_index, self.now_row = self.iter_env.next()\n",
    "        except StopIteration:\n",
    "            pass\n",
    "\n",
    "    def simulate(self, cost=None):\n",
    "        start_time = time.time()\n",
    "\n",
    "        for i in range(self.random_rounds):\n",
    "            for l in range(len(self.env)):\n",
    "#             for l in range(len(self.env_arr)): # Numpy option\n",
    "                self.update(cost)\n",
    "            self.reset()\n",
    "            if (i + 1) % 500 == 0:\n",
    "                print(self.asset_history_list[-1])\n",
    "                print(\"Round {} finished\".format(i + 1))\n",
    "#             print(self.asset_history_list[-1])\n",
    "#             print(\"Round {} finished\".format(i + 1))\n",
    "        print(\"{0} rounds of simulation with cost = {1}, took {2} seconds\".format(self.random_rounds, cost, time.time() - start_time))\n",
    "        return self.asset_history_list, self.action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data_full_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-666a92229d04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgod_chimp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChimpBot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data_full_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_random_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0masset_history_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgod_chimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'high'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masset_history_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data_full_pca' is not defined"
     ]
    }
   ],
   "source": [
    "god_chimp = ChimpBot(new_data_full_pca, iter_random_rounds=20000, gamma=0.9, random_state=0)\n",
    "asset_history_list, action_list = god_chimp.simulate(cost='high')\n",
    "\n",
    "print(pd.Series(action_list).describe())\n",
    "print(asset_history_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asset_history_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-eb8094e9f01a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masset_history_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'asset_history_list' is not defined"
     ]
    }
   ],
   "source": [
    "pd.Series(asset_history_list).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asset_history_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-af8d3d54665d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masset_history_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masset_history_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'asset_history_list' is not defined"
     ]
    }
   ],
   "source": [
    "(np.sign(pd.Series(asset_history_list)) * np.log(np.abs(pd.Series(asset_history_list)) + 1)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-15d0087f5d18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert Q-Table to Dataframe from the God Chimp (full dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0miter_random_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgod_chimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_dict_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgod_chimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_dict_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert Q-Table to Dataframe from the God Chimp (full dataset)\n",
    "iter_random_rounds=20000\n",
    "result_dict = defaultdict(list)\n",
    "for index, row in god_chimp.q_dict_analysis.iteritems():\n",
    "    for i in range(len(god_chimp.q_dict_analysis.keys()[0])):\n",
    "        column_name = 'col' + str(i + 1)\n",
    "        result_dict[column_name].append(index[i])\n",
    "    result_dict['Q'].append(god_chimp.q_dict_analysis[index][0])\n",
    "    result_dict['Date'].append(god_chimp.q_dict_analysis[index][1])\n",
    "\n",
    "god_chimp_q_df = pd.DataFrame(result_dict)\n",
    "\n",
    "# Yes share column removed\n",
    "column_list = ['col' + str(x) for x in range(1, 301 + 1)]\n",
    "column_list.extend(['Date', 'Q'])\n",
    "god_chimp_q_df = god_chimp_q_df[column_list]\n",
    "god_chimp_q_df.sort_values('Date', inplace=True)\n",
    "god_chimp_q_df.reset_index(inplace=True)\n",
    "del god_chimp_q_df['index']\n",
    "\n",
    "god_chimp_q_df.reset_index(inplace=True)\n",
    "del god_chimp_q_df['index']\n",
    "\n",
    "god_chimp_q_df.set_index(god_chimp_q_df['Date'], inplace=True)\n",
    "del god_chimp_q_df.index.name\n",
    "del god_chimp_q_df['Date']\n",
    "\n",
    "print(len(god_chimp_q_df))\n",
    "display(god_chimp_q_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data_full_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-fd0dbf2c65f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgod_chimp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChimpBot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data_full_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_random_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0masset_history_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgod_chimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'high'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masset_history_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data_full_pca' is not defined"
     ]
    }
   ],
   "source": [
    "god_chimp = ChimpBot(new_data_full_pca, iter_random_rounds=5000, gamma=0.75, random_state=0)\n",
    "asset_history_list, action_list = god_chimp.simulate(cost='high')\n",
    "\n",
    "print(pd.Series(action_list).describe())\n",
    "print(asset_history_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-ac1ccf9bc746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert Q-Table to Dataframe from the God Chimp (full dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0miter_random_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgod_chimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_dict_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgod_chimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_dict_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert Q-Table to Dataframe from the God Chimp (full dataset)\n",
    "iter_random_rounds=5000\n",
    "result_dict = defaultdict(list)\n",
    "for index, row in god_chimp.q_dict_analysis.iteritems():\n",
    "    for i in range(len(god_chimp.q_dict_analysis.keys()[0])):\n",
    "        column_name = 'col' + str(i + 1)\n",
    "        result_dict[column_name].append(index[i])\n",
    "    result_dict['Q'].append(god_chimp.q_dict_analysis[index][0])\n",
    "    result_dict['Date'].append(god_chimp.q_dict_analysis[index][1])\n",
    "\n",
    "god_chimp_q_df = pd.DataFrame(result_dict)\n",
    "\n",
    "# Yes share column removed\n",
    "column_list = ['col' + str(x) for x in range(1, 301 + 1)]\n",
    "column_list.extend(['Date', 'Q'])\n",
    "god_chimp_q_df = god_chimp_q_df[column_list]\n",
    "god_chimp_q_df.sort_values('Date', inplace=True)\n",
    "god_chimp_q_df.reset_index(inplace=True)\n",
    "del god_chimp_q_df['index']\n",
    "\n",
    "god_chimp_q_df.reset_index(inplace=True)\n",
    "del god_chimp_q_df['index']\n",
    "\n",
    "god_chimp_q_df.set_index(god_chimp_q_df['Date'], inplace=True)\n",
    "del god_chimp_q_df.index.name\n",
    "del god_chimp_q_df['Date']\n",
    "\n",
    "print(len(god_chimp_q_df))\n",
    "display(god_chimp_q_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'god_chimp_q_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-9f2b6adc08c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgod_chimp_q_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgod_chimp_q_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgod_chimp_q_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'god_chimp_q_df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(god_chimp_q_df.ix[:, -2])\n",
    "print(le.classes_)\n",
    "god_chimp_q_df.ix[:, -2] = le.transform(god_chimp_q_df.ix[:, -2])\n",
    "\n",
    "# = god_chimp_q_df.ix[:, -2].apply(action_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'god_chimp_q_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-97289dbba162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfs_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgod_chimp_q_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfs_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfs_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'god_chimp_q_df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "fs_data = god_chimp_q_df\n",
    "fs_X = fs_data.ix[:, :-1]\n",
    "fs_y = fs_data.ix[:, -1]\n",
    "names = list(fs_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fs_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-dea849c1bbab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m37\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fs_X' is not defined"
     ]
    }
   ],
   "source": [
    "estimator = SVR(kernel=\"linear\")\n",
    "rfe = RFE(estimator, 37, step=1)\n",
    "rfe = rfe.fit(fs_X, fs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RFE' object has no attribute 'ranking_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-b22f7b70966a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrfe_ranking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranking_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Features sorted by their rank:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe_ranking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RFE' object has no attribute 'ranking_'"
     ]
    }
   ],
   "source": [
    "rfe_ranking = sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names))\n",
    "print(\"Features sorted by their rank:\")\n",
    "print(rfe_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfe_ranking' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-e2671c5e3315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrfe_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe_ranking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrfe_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe_cols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m37\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rfe_ranking' is not defined"
     ]
    }
   ],
   "source": [
    "rfe_cols = [x[1] for i, x in enumerate(rfe_ranking)]\n",
    "rfe_cols = rfe_cols[:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fs_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-282ab000677f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrlasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'aic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrlasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mrlasso_ranking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrlasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Features sorted by their score:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fs_X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RandomizedLasso\n",
    "\n",
    "rlasso = RandomizedLasso(alpha='aic')\n",
    "rlasso.fit(fs_X, fs_y)\n",
    "rlasso_ranking = sorted(zip(map(lambda x: round(x, 4), rlasso.scores_), names), reverse=True)\n",
    "print \"Features sorted by their score:\"\n",
    "print(rlasso_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rlasso_ranking' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-c93b1ea1d5fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 24 features before the drop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlasso_ranking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rlasso_ranking' is not defined"
     ]
    }
   ],
   "source": [
    "# 24 features before the drop\n",
    "plt.plot([x[0] for i, x in enumerate(rlasso_ranking)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rlasso_ranking' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-9fe7c5139be7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrlasso_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlasso_ranking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlasso_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrlasso_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrlasso_cols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rlasso_ranking' is not defined"
     ]
    }
   ],
   "source": [
    "rlasso_cols = [x[1] for i, x in enumerate(rlasso_ranking) if x[0] >= 0.95]\n",
    "print(len(rlasso_cols))\n",
    "rlasso_cols = rlasso_cols[:96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfe_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-5807f3ac1af9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreduced_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# reduced_columns.extend(rlasso_cols)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mreduced_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mreduced_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'col301'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mreduced_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rfe_cols' is not defined"
     ]
    }
   ],
   "source": [
    "# reduced_columns = ['col' + str(x) for x in range(1, 11)]\n",
    "reduced_columns = []\n",
    "# reduced_columns.extend(rlasso_cols)\n",
    "reduced_columns.extend(rfe_cols)\n",
    "reduced_columns.extend(['col301', 'Q'])\n",
    "reduced_columns = list(set(reduced_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(reduced_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'god_chimp_q_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-11919e6c34a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgod_chimp_q_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgod_chimp_q_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduced_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maction_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgod_chimp_q_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'col301'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgod_chimp_q_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maction_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'god_chimp_q_df' is not defined"
     ]
    }
   ],
   "source": [
    "god_chimp_q_df = god_chimp_q_df[reduced_columns]\n",
    "\n",
    "action_idx = god_chimp_q_df.columns.get_loc('col301')\n",
    "cols = god_chimp_q_df.columns.tolist()\n",
    "cols = cols[:action_idx] + cols[action_idx + 1:] + [cols[action_idx]]\n",
    "god_chimp_q_df = god_chimp_q_df.reindex(columns=cols)\n",
    "\n",
    "q_idx = god_chimp_q_df.columns.get_loc('Q')\n",
    "cols = god_chimp_q_df.columns.tolist()\n",
    "cols = cols[:q_idx] + cols[q_idx + 1:] + [cols[q_idx]]\n",
    "god_chimp_q_df = god_chimp_q_df.reindex(columns=cols)\n",
    "\n",
    "# god_chimp_q_df.ix[:, -2] = god_chimp_q_df.ix[:, -2].apply(action_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def find_best_training_size(data_full, full_q_df, training_sizes, testing_size, target_data, random_state=0):\n",
    "    start_time = time.time()\n",
    "    accs = []\n",
    "    d_counter = 0\n",
    "\n",
    "    # Loop through all batches in validation dataset\n",
    "    (u, ) = data_full.index.get_indexer_for([target_data.index[0]])\n",
    "    for d in range(u, u + testing_size * (len(target_data) // testing_size), testing_size):\n",
    "        acc_num_train_months = []\n",
    "        d_counter += 1\n",
    "\n",
    "        # Dates in the batch\n",
    "        date_range = data_full.iloc[d:d + testing_size].index\n",
    "        \n",
    "        # Loop through all sizes of training sets\n",
    "        for num_train_month in range(1, training_sizes + 1):  \n",
    "            # Prepare Training/Testing Datasets\n",
    "            X_train = full_q_df.iloc[d - (int(21 * num_train_month)):d, :-1]\n",
    "            y_train = full_q_df.iloc[d - (int(21 * num_train_month)):d, -1]\n",
    "            X_test = full_q_df.ix[date_range, :-1]\n",
    "            y_test = full_q_df.ix[date_range, -1]\n",
    "\n",
    "            # Fit data and make predictions\n",
    "            reg = GradientBoostingRegressor()\n",
    "#             reg = KNeighborsRegressor(n_neighbors=5, weights='distance', n_jobs=-1)\n",
    "#             reg = LinearRegression(n_jobs=-1)\n",
    "#             reg = SVR(kernel='rbf')\n",
    "#             reg = XGBRegressor()\n",
    "            reg = RandomForestRegressor(n_estimators=1500, max_features='auto', oob_score=True, n_jobs=-1, random_state=random_state)\n",
    "            reg.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = reg.predict(X_test)\n",
    "            y_fit = reg.predict(X_train)\n",
    "\n",
    "            pred_q = y_pred\n",
    "            actions = X_test.ix[:, -1]\n",
    "            data = {'Action': actions, 'Q': pred_q}\n",
    "            df_pred = pd.DataFrame(data=data, index=y_test.index)\n",
    "\n",
    "            pred_actions = []\n",
    "\n",
    "            for date in date_range:  \n",
    "                max_q = [0, -1]\n",
    "                for i, r in df_pred.ix[date].iterrows():\n",
    "                    if r['Q'] > max_q[1]:\n",
    "                        max_q = [r['Action'], r['Q']]\n",
    "                pred_actions.append(max_q[0])\n",
    "\n",
    "            best_actions = []\n",
    "\n",
    "            for date in date_range:\n",
    "                max_q = [0, -1]\n",
    "                for i, r in full_q_df.ix[date].iterrows():\n",
    "                    if r['Q'] > max_q[1]:\n",
    "                        max_q = [r[-2], r['Q']]\n",
    "                best_actions.append(max_q[0])\n",
    "\n",
    "            acc_num_train_months.append(accuracy_score(best_actions, pred_actions))\n",
    "        accs.append(np.array(acc_num_train_months))\n",
    "        print(\"Batch {0} completed....{1:.2f}%\".format(d_counter, 100 * (d_counter / len(range(u, u + testing_size * (len(target_data) // testing_size), testing_size)))))\n",
    "        geo_means = np.power(reduce(lambda x,y: x*y, accs), (1/len(accs)))\n",
    "        arithmetic_means = reduce(lambda x,y: x+y, accs) / len(accs)\n",
    "        print(\"Geometric Means Max: {}\".format((np.argmax(geo_means) + 1, np.max(geo_means))))\n",
    "        print(\"Arithemtic Means Max: {}\".format((np.argmax(arithmetic_means) + 1, np.max(arithmetic_means))))\n",
    "    \n",
    "    print(\"Grid search best num_train_year took {} seconds:\".format(time.time() - start_time))\n",
    "    \n",
    "    return (geo_means, arithmetic_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data_full_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-f39bd43f9739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_training_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_full\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_data_full_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_q_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgod_chimp_q_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_phase_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgeo_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0marithmetic_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data_full_pca' is not defined"
     ]
    }
   ],
   "source": [
    "means = find_best_training_size(data_full=new_data_full_pca, full_q_df=god_chimp_q_df, training_sizes=120, testing_size=5, target_data=validation_phase_data, random_state=0)\n",
    "geo_means = means[0]\n",
    "arithmetic_means = means[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geo_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-7439754c0bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgeo_means\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marithmetic_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marithmetic_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marithmetic_means\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'geo_means' is not defined"
     ]
    }
   ],
   "source": [
    "print(geo_means)\n",
    "print(sorted(range(len(geo_means)), key=lambda k: geo_means[k], reverse=True))\n",
    "\n",
    "print(arithmetic_means)\n",
    "print(sorted(range(len(arithmetic_means)), key=lambda k: arithmetic_means[k], reverse=True))\n",
    "\n",
    "validation_phase_data['Trade Price'].plot()\n",
    "plt.figure()\n",
    "plt.plot(geo_means)\n",
    "plt.figure()\n",
    "plt.plot(arithmetic_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search(data_full, full_q_df, training_size, testing_size, target_data, random_state=0):\n",
    "    start_time = time.time()\n",
    "    accs = []\n",
    "    d_counter = 0\n",
    "#     feature_importance_list = []\n",
    "    best_param_list = []\n",
    "\n",
    "    # Loop through all batches in validation dataset\n",
    "    (u, ) = data_full.index.get_indexer_for([target_data.index[0]])\n",
    "    for d in range(u, u + testing_size * (len(target_data) // testing_size), testing_size):\n",
    "        acc_num_train_months = []\n",
    "        d_counter += 1\n",
    "\n",
    "        # Dates in the batch\n",
    "        date_range = data_full.iloc[d:d + testing_size].index\n",
    "        \n",
    "        # Loop through all sizes of training sets\n",
    "        num_train_month = training_size\n",
    "        # Prepare Training/Testing Datasets\n",
    "        X_train = full_q_df.iloc[d - (int(21 * num_train_month)):d, :-1]\n",
    "        y_train = full_q_df.iloc[d - (int(21 * num_train_month)):d, -1]\n",
    "        X_test = full_q_df.ix[date_range, :-1]\n",
    "        y_test = full_q_df.ix[date_range, -1]\n",
    "\n",
    "        # Fit data and make predictions\n",
    "#         reg = GradientBoostingRegressor()\n",
    "#         param_grid = {'n_estimators': [100, 200, 300, 400, 500], 'learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3], 'min_samples_leaf': [1, 5, 10, 20, 50]}\n",
    "#         reg = KNeighborsRegressor(n_jobs=-1)\n",
    "#         param_grid = {'n_neighbors': [5, 10, 15, 20, 40, 80], 'weights': ['uniform', 'distance']}\n",
    "        reg = RandomForestRegressor(n_estimators=128, max_features='sqrt', n_jobs=-1, random_state=random_state)\n",
    "#         param_grid = {'n_estimators': [128, 1500], 'max_features': ['auto'], 'min_samples_leaf': [1, 10, 50]}\n",
    "\n",
    "#         reg_gs = GridSearchCV(reg, param_grid, scoring='neg_mean_squared_error')\n",
    "        reg.fit(X_train, y_train)\n",
    "#         best_param_list.append(reg_gs.best_params_)\n",
    "\n",
    "#         # Create feature importance histogram\n",
    "#         feature_importance_list.append(reg.feature_importances_)\n",
    "    \n",
    "#         vif = [int(np.argmax(x)) for x in feature_importance_list]\n",
    "#         vif = pd.DataFrame(vif)\n",
    "\n",
    "        y_pred = reg.predict(X_test)\n",
    "        y_fit = reg.predict(X_train)\n",
    "\n",
    "        pred_q = y_pred\n",
    "        actions = X_test.ix[:, -1]\n",
    "        data = {'Action': actions, 'Q': pred_q}\n",
    "        df_pred = pd.DataFrame(data=data, index=y_test.index)\n",
    "\n",
    "        pred_actions = []\n",
    "\n",
    "        for date in date_range:  \n",
    "            max_q = [0, -1]\n",
    "            for i, r in df_pred.ix[date].iterrows():\n",
    "                if r['Q'] > max_q[1]:\n",
    "                    max_q = [r['Action'], r['Q']]\n",
    "            pred_actions.append(max_q[0])\n",
    "\n",
    "        best_actions = []\n",
    "\n",
    "        for date in date_range:\n",
    "            max_q = [0, -1]\n",
    "            for i, r in full_q_df.ix[date].iterrows():\n",
    "                if r['Q'] > max_q[1]:\n",
    "                    max_q = [r[-2], r['Q']]\n",
    "            best_actions.append(max_q[0])\n",
    "\n",
    "        acc_num_train_months.append(accuracy_score(best_actions, pred_actions))\n",
    "\n",
    "        accs.append(np.array(acc_num_train_months))\n",
    "        print(\"Batch {0} completed....{1:.2f}%\".format(d_counter, 100 * (d_counter / len(range(u, u + testing_size * (len(target_data) // testing_size), testing_size)))))\n",
    "        geo_means = np.power(reduce(lambda x,y: x*y, accs), (1/len(accs)))\n",
    "        arithmetic_means = reduce(lambda x,y: x+y, accs) / len(accs)\n",
    "        print(\"Geometric Means Max: {}\".format((np.argmax(geo_means) + 1, np.max(geo_means))))\n",
    "        print(\"Arithemtic Means Max: {}\".format((np.argmax(arithmetic_means) + 1, np.max(arithmetic_means))))\n",
    "    \n",
    "    print(\"Grid search best num_train_year took {} seconds:\".format(time.time() - start_time))\n",
    "    \n",
    "    return (geo_means, arithmetic_means, best_param_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data_full_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-0ff3520fc67f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_full\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_data_full_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_q_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgod_chimp_q_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_phase_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgeo_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0marithmetic_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data_full_pca' is not defined"
     ]
    }
   ],
   "source": [
    "results = grid_search(data_full=new_data_full_pca, full_q_df=god_chimp_q_df, training_size=35, testing_size=7, target_data=validation_phase_data, random_state=0)\n",
    "geo_means = results[0]\n",
    "arithmetic_means = results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-160098eda582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpv_history_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnew_data_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mnew_data_features_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnew_data_features_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_transform_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data_features_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data_features_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data_full' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Start simulation for the chimp ------ get new full q_df\n",
    "start_time = time.time()\n",
    "\n",
    "num_iter = 1500\n",
    "day_count = 0\n",
    "pv_history_list = []\n",
    "\n",
    "new_data_features = new_data_full.ix[:, :-1]\n",
    "new_data_features_norm = normalization(new_data_features, new_data_features)\n",
    "new_data_features_pca = pca_transform_reconstruct(new_data_features_norm, new_data_features_norm)\n",
    "new_data_full_norm2 = normalization(new_data_feature_pca, new_data_features_pca)\n",
    "\n",
    "new_data_full_norm2['Trade Price'] = new_data_full.ix[:, 'Trade Price']\n",
    "new_data_full = new_data_full_norm2\n",
    "\n",
    "# display(new_data_full.isnull().sum())\n",
    "# display(new_data_full.describe())\n",
    "display(new_data_full.head())\n",
    "\n",
    "\n",
    "chimp_analytics = EnhancedChimpBot(new_data_full)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(num_iter):\n",
    "    for l in range(len(chimp_analytics.env)):\n",
    "        chimp_analytics.update()\n",
    "    pv_history_list.append(chimp_analytics.cash + chimp_analytics.pv)\n",
    "    chimp_analytics.reset()\n",
    "\n",
    "print(\"{0} rounds of training took {1} seconds\".format(num_iter, time.time() - start_time))\n",
    "\n",
    "print(pv_history_list[-1])\n",
    "\n",
    "# Convert Q-Table to Dataframe from trained chimp (full)\n",
    "result_dict = defaultdict(list)\n",
    "for index, row in chimp_analytics.q_dict_analysis.iteritems():\n",
    "    for i in range(len(chimp_analytics.q_dict_analysis.keys()[0])):\n",
    "        column_name = 'col' + str(i + 1)\n",
    "        result_dict[column_name].append(index[i])\n",
    "    result_dict['Q'].append(chimp_analytics.q_dict_analysis[index][0])\n",
    "    result_dict['Date'].append(chimp_analytics.q_dict_analysis[index][1])\n",
    "\n",
    "new_full_q_df = pd.DataFrame(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_full_q_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-6f31fd9fb53e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew_column_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'col'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m247\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnew_column_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_full_q_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_full_q_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_column_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnew_full_q_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_full_q_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mnew_full_q_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_full_q_df' is not defined"
     ]
    }
   ],
   "source": [
    "new_column_list = ['col' + str(x) for x in range(1, 247 + 1)]\n",
    "new_column_list.extend(['Q'])\n",
    "new_full_q_df = new_full_q_df[new_column_list]\n",
    "new_full_q_df = new_full_q_df.sort_index()\n",
    "del new_full_q_df.index.name\n",
    "\n",
    "display(new_full_q_df.head())\n",
    "print(type(new_full_q_df.index[0]))\n",
    "\n",
    "new_full_q_df['col247'] = new_full_q_df['col247'].apply(action_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-f032054f43b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Loop through all batches in validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_phase_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtesting_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m252\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtesting_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0macc_num_train_months\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data_full' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "accs = []\n",
    "\n",
    "training_sizes = 48\n",
    "testing_size = 7\n",
    "\n",
    "# Loop through all batches in validation dataset\n",
    "(u, ) = new_data_full.index.get_indexer_for([validation_phase_data.index[0]])\n",
    "for d in range(u, u + testing_size * (252 // testing_size), testing_size):\n",
    "    acc_num_train_months = []\n",
    "    \n",
    "#     Dates in the batch\n",
    "    date_range = new_data_full.iloc[d:d + testing_size].index\n",
    "    \n",
    "    # Loop through all sizes of training sets\n",
    "    for num_train_month in range(1, training_sizes + 1):  \n",
    "#     for num_train_month in range(1, 240 + 1):\n",
    "        # Prepare Training/Testing Datasets\n",
    "        X_train = new_full_q_df.iloc[d - (int(21 * num_train_month)):d, :-1]\n",
    "        y_train = new_full_q_df.iloc[d - (int(21 * num_train_month)):d, -1]\n",
    "        X_test = new_full_q_df.ix[date_range, :-1]\n",
    "        y_test = new_full_q_df.ix[date_range, -1]\n",
    "        \n",
    "        # Fit data and make predictions\n",
    "        reg = RandomForestRegressor(n_estimators=1500, max_features='sqrt', oob_score=True, n_jobs=-1, random_state=0)\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = reg.predict(X_test)\n",
    "        y_fit = reg.predict(X_train)\n",
    "\n",
    "        pred_q = y_pred\n",
    "        actions = X_test['col247']\n",
    "        data = {'Action': actions, 'Q': pred_q}\n",
    "        df_pred = pd.DataFrame(data=data, index=y_test.index)\n",
    "\n",
    "        pred_actions = []\n",
    "\n",
    "        for date in date_range:  \n",
    "            max_q = [0, -1]\n",
    "            for i, r in df_pred.ix[date].iterrows():\n",
    "                if r['Q'] > max_q[1]:\n",
    "                    max_q = [r['Action'], r['Q']]\n",
    "            pred_actions.append(max_q[0])\n",
    "            \n",
    "        best_actions = []\n",
    "\n",
    "        for date in date_range:\n",
    "            max_q = [0, -1]\n",
    "            for i, r in new_full_q_df.ix[date].iterrows():\n",
    "                if r['Q'] > max_q[1]:\n",
    "                    max_q = [r['col247'], r['Q']]\n",
    "            best_actions.append(max_q[0])\n",
    "\n",
    "        acc_num_train_months.append(accuracy_score(best_actions, pred_actions))\n",
    "    accs.append(np.array(acc_num_train_months))\n",
    "    print(\"Batch {0} completed. Total progress {1}%\".format(d + 1 - u, d / (u + testing_size * (252 // testing_size))))\n",
    "    harmonic_means = np.power(reduce(lambda x,y: x*y, accs), (1/len(accs)))\n",
    "    arithmetic_means = reduce(lambda x,y: x+y, accs) / len(accs)\n",
    "    print(\"Harmonic Means Max: {}\".format((np.argmax(harmonic_means) + 1, np.max(harmonic_means))))\n",
    "    print(\"Arithemtic Means Max: {}\".format((np.argmax(arithmetic_means) + 1, np.max(arithmetic_means))))\n",
    "    \n",
    "print(\"Grid search best num_train_year took {} seconds:\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calvinjku/anaconda2/envs/python2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/calvinjku/anaconda2/envs/python2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import grid_search\n",
    "\n",
    "class ChimpBot(MonkeyBot):\n",
    "    \"\"\"An agent that learns to drive in the smartcab world.\"\"\"\n",
    "    num_features = 246\n",
    "    valid_actions = ['Buy', 'Sell']\n",
    "\n",
    "    num_trial = 500\n",
    "    trial_counter = 0 # For getting the trial number\n",
    "\n",
    "    random_rounds = 1500 # Number of rounds where the bot chooses to go monkey\n",
    "\n",
    "    trial_meta_info = {} # For monitoring what happens in each trial\n",
    "\n",
    "    epsilon = 1\n",
    "    gamma = 0.75\n",
    "    random_reward = [0]\n",
    "\n",
    "    random_counter = 0\n",
    "    policy_counter = 0\n",
    "\n",
    "    track_key1 = {'Sell': 0, 'Buy': 0, 'Hold': 0}\n",
    "    track_key2 = {'Sell': 0, 'Buy': 0, 'Hold': 0}\n",
    "\n",
    "    track_random_decision = {'Sell': 0, 'Buy': 0, 'Hold': 0}\n",
    "\n",
    "    reset_counter = 0\n",
    "\n",
    "    def __init__(self, dfEnv, cash=1000, share=0, pv=0):\n",
    "        super(ChimpBot, self).__init__(dfEnv, cash, share, pv)\n",
    "        # sets self.cash = 1000\n",
    "        # sets self.share = 0\n",
    "        # sets self.pv = 0\n",
    "        # sets self.pv_history_list = []\n",
    "        # sets self.env = dfEnv\n",
    "        # implements buy(self, stock_price)\n",
    "        # implements sell(self, stock_price)\n",
    "        # implements hold(self)\n",
    "\n",
    "        self.iter_env = self.env.iterrows()\n",
    "        self.now_env_index, self.now_row = self.iter_env.next()\n",
    "\n",
    "        # self.now_yes_share = 0\n",
    "        self.now_action = ''\n",
    "        # self.now_q = 0\n",
    "\n",
    "        self.prev_cash = self.cash\n",
    "        self.prev_share = self.share\n",
    "        self.prev_pv = self.pv\n",
    "\n",
    "        self.q_df_columns = list(self.env.columns)\n",
    "        self.q_df_columns.pop()\n",
    "        self.q_df_columns.extend(['Action', 'Q Value'])\n",
    "        self.q_df = pd.DataFrame(columns=self.q_df_columns)\n",
    "        self.q_dict = defaultdict(lambda: (0, 0)) # element of q_dict is (state, act): (q_value, t)\n",
    "        self.q_dict_analysis = defaultdict(lambda: (0, 0))\n",
    "\n",
    "        self.negative_reward = 0\n",
    "        self.n_reward_hisotry = []\n",
    "        self.net_reward = 0\n",
    "\n",
    "        self.reset_counter = 0\n",
    "\n",
    "        # Smartcab use only\n",
    "        # self.penalty = False\n",
    "        # self.num_step = 0 # Number of steps for each trial; get reset each time a new trial begins\n",
    "\n",
    "    def make_q_df(self):\n",
    "        result_dict = defaultdict(list)\n",
    "\n",
    "        for index, row in self.q_dict.iteritems():\n",
    "            for i in range(len(self.q_dict.keys()[0])):\n",
    "                column_name = 'col' + str(i + 1)\n",
    "                result_dict[column_name].append(index[i])\n",
    "            result_dict['Q'].append(self.q_dict[index][0])\n",
    "\n",
    "        self.q_df = pd.DataFrame(result_dict)\n",
    "        q_df_column_list = ['col' + str(x) for x in range(1, self.num_features + 1 + 1)]\n",
    "        q_df_column_list.append('Q')\n",
    "        # q_df_column_list = ['col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9', 'col10', 'col11', 'col12', 'col13', 'col14', 'col15', 'col16', 'col17', 'col18', 'col19', 'col20', 'col21', 'col22', 'col23', 'col24', 'col25', 'col26', 'col27', 'col28', 'col29', 'col30', 'col31', 'col32', 'col33', 'col34', 'col35', 'col36', 'col37', 'col38', 'col39', 'Q']\n",
    "        self.q_df = self.q_df[q_df_column_list]\n",
    "\n",
    "        def transfer_action(x):\n",
    "            if x == 'Buy':\n",
    "                return 1\n",
    "            elif x == 'Sell':\n",
    "                return 2\n",
    "            elif x == 'Hold':\n",
    "                return 0\n",
    "            else:\n",
    "                raise ValueError(\"Wrong action!\")\n",
    "\n",
    "        def str_float_int(x):\n",
    "            return int(float(x))\n",
    "\n",
    "        arr_int = np.vectorize(str_float_int)\n",
    "\n",
    "        self.q_df['col' + str(self.num_features + 1)] = self.q_df['col' + str(self.num_features + 1)].apply(transfer_action)\n",
    "        self.q_df.ix[:, :-1] = self.q_df.ix[:, :-1].apply(arr_int)\n",
    "\n",
    "    def split_q_df(self):\n",
    "        self.q_df_X = self.q_df.ix[:, :-1]\n",
    "        self.q_df_y = self.q_df.ix[:, -1]\n",
    "        # self.X_train, self.X_test, self.y_train, self.y_test = cross_validation.train_test_split(self.q_df_X, self.q_df_y, test_size=0.1, random_state=0)\n",
    "\n",
    "    def train_on_q_df(self):\n",
    "        reg = AdaBoostRegressor(DecisionTreeRegressor(max_depth=25), n_estimators=50, random_state=0)\n",
    "        self.q_reg = reg\n",
    "        self.q_reg = self.q_reg.fit(self.q_df_X, self.q_df_y)\n",
    "\n",
    "    def update_q_model(self):\n",
    "#         print(\"Updating Q model...\")\n",
    "        start_time = time.time()\n",
    "        self.make_q_df()\n",
    "        self.split_q_df()\n",
    "        self.train_on_q_df()\n",
    "#         print(\"Update took {} seconds\".format(time.time() - start_time))\n",
    "\n",
    "    def from_state_action_predict_q(self, state_action):\n",
    "        state_action = [state_action]\n",
    "\n",
    "        pred_q = self.q_reg.predict(state_action)\n",
    "\n",
    "        return pred_q\n",
    "\n",
    "    # def yes_share(self):\n",
    "    #     # Represent chimp asset in state_action\n",
    "    #     if self.share > 0:\n",
    "    #         return 1\n",
    "    #     else:\n",
    "    #         return 0\n",
    "\n",
    "    def max_q(self, now_row):\n",
    "        def transfer_action(x):\n",
    "            if x == 'Buy':\n",
    "                return 1\n",
    "            elif x == 'Sell':\n",
    "                return 2\n",
    "            elif x == 'Hold':\n",
    "                return 0\n",
    "            else:\n",
    "                raise ValueError(\"Wrong action!\")\n",
    "\n",
    "        def str_float_int(x):\n",
    "            return int(float(x))\n",
    "\n",
    "        now_row2 = list(now_row)\n",
    "        # now_row2.append(self.now_yes_share)\n",
    "        max_q = ''\n",
    "        q_compare_dict = {}\n",
    "\n",
    "        if len(now_row2) > self.num_features:\n",
    "            raise ValueError(\"Got ya bastard! @ MaxQ\")\n",
    "\n",
    "        # Populate the q_dict\n",
    "        for act in set(self.valid_actions):\n",
    "            now_row2.append(act)\n",
    "            now_row_key = tuple(now_row2)\n",
    "\n",
    "            _ = self.q_dict[now_row_key]\n",
    "\n",
    "            # # K-Q Algorithm\n",
    "            # if np.random.choice(2, p = [0.9, 0.1]) == 1 and len(self.q_dict) > 30000:\n",
    "            # if _[1] == 0 and np.random.choice(2, p = [0.7, 0.3]) == 1 and len(self.q_dict) > 30000:\n",
    "            try:\n",
    "                self.q_reg\n",
    "            except AttributeError:\n",
    "                pass\n",
    "                # print('No q_reg yet...going with default.')\n",
    "            else:\n",
    "                if _[1] == 0:\n",
    "                    # print(\"Dreaming mode...\")\n",
    "                    # start_time = time.time()\n",
    "                    # self.update_q_model()\n",
    "\n",
    "                    single_X = np.array(now_row_key)\n",
    "                    # print(single_X)\n",
    "                    arr_int = np.vectorize(str_float_int)\n",
    "                    single_X[-1] = transfer_action(single_X[-1])\n",
    "                    single_X = arr_int(single_X)\n",
    "                    single_X = single_X.reshape(1, -1)\n",
    "                    pred_q = self.q_reg.predict(single_X)\n",
    "                    dreamed_q = (1 - (1 / (self.q_dict[now_row_key][1] + 1))) * self.q_dict[now_row_key][0] + (1 / (self.q_dict[now_row_key][1] + 1)) * pred_q[0]\n",
    "                    self.q_dict[now_row_key] = (dreamed_q, self.q_dict[now_row_key][1] + 1)\n",
    "                    # print(\"Q-dreamed: {0} for Act: {1}, taking {2} seconds.\".format(self.q_dict[now_row_key], act, time.time() - start_time))\n",
    "\n",
    "            # print(act, self.q_dict[now_row_key])\n",
    "\n",
    "            q_compare_dict[now_row_key] = self.q_dict[now_row_key]\n",
    "            now_row2.pop()\n",
    "\n",
    "        try:\n",
    "            max(q_compare_dict.iteritems(), key=lambda x:x[1])\n",
    "        except ValueError:\n",
    "            print(\"Wrong Q Value in Q Compare Dict!\")\n",
    "        else:\n",
    "            key, qAndT = max(q_compare_dict.iteritems(), key=lambda x:x[1])\n",
    "            # print(\"Action: {0}, with Q-value: {1}\".format(key[-1], qAndT[0]))\n",
    "            return key[-1], qAndT[0], qAndT[1]\n",
    "\n",
    "    def q_update(self):\n",
    "        # print(\"Data Index: {}\".format(self.now_env_index))\n",
    "        now_states = list(self.now_row)\n",
    "        # now_states = list(now_states)\n",
    "        now_states.pop() # disregard the Trade Price\n",
    "\n",
    "        prev_states = list(self.prev_states)\n",
    "\n",
    "        if len(prev_states) > self.num_features:\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update...something wrong with the self.prev_states!!!\")\n",
    "\n",
    "        # prev_states.append(self.prev_yes_share)\n",
    "        prev_states.append(self.prev_action)\n",
    "        prev_states_key = tuple(prev_states)\n",
    "\n",
    "        if len(prev_states_key) > self.num_features + 2:\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update\")\n",
    "\n",
    "        q_temp = self.q_dict[prev_states_key]\n",
    "\n",
    "        q_temp0 = (1 - (1 / (q_temp[1] + 1))) * q_temp[0] + (1 / (q_temp[1] + 1)) * (self.reward + self.gamma * self.max_q(now_states)[1])\n",
    "\n",
    "        if prev_states_key[:-1] == ('Low', 'Low', 'Average', 'Average', 'Low', 'Average', 'Average', 'Average', 'Low', 'Low', 'Low', 'Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'N-Very Low', 'Low', 'Average', 'N-Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'High', 'Yes'):\n",
    "            self.track_key1[prev_states_key[-1]] += 1\n",
    "        elif prev_states_key[:-1] == ('Low', 'Low', 'Average', 'Average', 'Low', 'Average', 'Average', 'Average', 'Low', 'Low', 'Low', 'Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'N-Very Low', 'Low', 'Average', 'N-Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'High', 'No'):\n",
    "            self.track_key2[prev_states_key[-1]] += 1\n",
    "        # elif prev_states_key[:-1] == ('Very High', 'Very High', 'Very High', 'Very High', 'Very High', 'Very High', 'Average', 'High', 'Average', 'Average', 'Average', 'Low', 'Average', 'Very Low', 'Low', 'N-Very Low', 'N-Very Low', 'N-Very Low', 'N-Very Low', 'Very Low', 'Very Low', 'Average', 'Very Low', 'Low', 'Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Low', 'Very Low', 'Low', 'Very Low', 'Average', 'No'):\n",
    "        #     self.track_key2[prev_states_key[-1]] += 1\n",
    "\n",
    "        self.q_dict[prev_states_key] = (q_temp0, q_temp[1] + 1)\n",
    "        # For analysis purpose\n",
    "        self.q_dict_analysis[prev_states_key] = (q_temp0, self.prev_env_index)\n",
    "        # print(\"Now Action: {}\".format())\n",
    "        # print(prev_states_key)\n",
    "        return (self.q_dict[prev_states_key])\n",
    "\n",
    "    def policy(self, now_row):\n",
    "        return self.max_q(now_row)[0]\n",
    "\n",
    "    def reset(self):\n",
    "        # Portfolio change over iterations\n",
    "        self.pv_history_list.append(self.pv + self.cash)\n",
    "\n",
    "        self.iter_env = self.env.iterrows()\n",
    "        self.now_env_index, self.now_row = self.iter_env.next()\n",
    "\n",
    "        self.cash = 1000\n",
    "        self.share = 0\n",
    "        self.pv = 0\n",
    "\n",
    "        self.prev_cash = self.cash\n",
    "        self.prev_share = self.share\n",
    "        self.prev_pv = self.pv\n",
    "\n",
    "        if self.epsilon - 1/self.random_rounds > 0.001: # Epislon threshold: 0.01\n",
    "            self.random_counter += 1\n",
    "            self.epsilon = self.epsilon - 1/self.random_rounds\n",
    "        else:\n",
    "            self.epsilon = 0.001 # Epislon threshold: 0.1\n",
    "            self.policy_counter += 1\n",
    "\n",
    "        self.net_reward = 0\n",
    "\n",
    "        self.reset_counter += 1\n",
    "\n",
    "        if self.reset_counter % random_rounds == 0:\n",
    "            self.update_q_model()\n",
    "\n",
    "        # self.num_step = 0 # Recalculate the steps for the new trial\n",
    "        # self.penalty = False\n",
    "        # self.fail = False\n",
    "\n",
    "    def make_decision(self, now_row):\n",
    "        return self.policy(now_row)\n",
    "\n",
    "    def update(self):\n",
    "        # Update state\n",
    "        now_states = list(self.now_row)\n",
    "\n",
    "        if len(now_states) > self.num_features + 1:\n",
    "            print(len(now_states))\n",
    "            print(self.num_features)\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update...something wrong with the self.now_row!!!\")\n",
    "\n",
    "        # now_states = list(now_states)\n",
    "        # print(type(self.now_row))\n",
    "        now_states.pop() # disregard the Trade Price\n",
    "\n",
    "        if len(now_states) > self.num_features:\n",
    "            print(now_states)\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update...something wrong with now_states after pop!!!\")\n",
    "\n",
    "        # Exploitation-exploration decisioning\n",
    "        random.seed(datetime.now())\n",
    "        self.decision = np.random.choice(2, p = [self.epsilon, 1 - self.epsilon]) # decide to go random or with the policy\n",
    "        # self.decision = 0 # Force random mode\n",
    "\n",
    "        # print(\"Random decision: {0}, Epislon: {1}\".format(self.decision, self.epsilon))\n",
    "        # print(\"What the FUCK?!\")\n",
    "        if self.decision == 0: # if zero, go random\n",
    "            random.seed(datetime.now())\n",
    "            action = random.choice(self.valid_actions)\n",
    "            # if tuple(now_states) == ('Low', 'Low', 'Average', 'Average', 'Low', 'Average', 'Average', 'Average', 'Low', 'Low', 'Low', 'Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'N-Very Low', 'Low', 'Average', 'N-Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'Very Low', 'High'):\n",
    "            #     self.track_random_decision[action] += 1\n",
    "        else: # else go with the policy\n",
    "            # print(\"now_states: {}\".format(now_states))\n",
    "            # self.now_yes_share = self.yes_share()\n",
    "            action = self.make_decision(now_states)\n",
    "\n",
    "        if len(now_states) > self.num_features:\n",
    "            print(now_states)\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update...something wrong with now_states after make_decision!!!\")\n",
    "\n",
    "        # print(\"Now Action Real: {}\".format(action))\n",
    "        # Execute action and get reward\n",
    "        if action == 'Buy':\n",
    "            # print(self.now_row)\n",
    "            self.buy(self.now_row[-1])\n",
    "        elif action == 'Sell':\n",
    "            # print(self.now_row)\n",
    "            self.sell(self.now_row[-1])\n",
    "        elif action == 'Hold':\n",
    "            # print(self.now_row)\n",
    "            self.hold(self.now_row[-1])\n",
    "        else:\n",
    "            raise ValueError(\"Wrong action man!\")\n",
    "\n",
    "        try:\n",
    "            self.prev_states\n",
    "        except AttributeError:\n",
    "            print(\"Running the first time...no prevs exist.\")\n",
    "        else:\n",
    "            self.reward = ((self.cash - self.prev_cash) + (self.pv - self.prev_pv)) / (self.prev_cash + self.prev_pv)\n",
    "            self.q_update()\n",
    "\n",
    "        self.prev_states = now_states\n",
    "\n",
    "        if len(now_states) > self.num_features:\n",
    "            raise ValueError(\"Got ya bastard! @ Q_Update...something wrong with the now_states!!!\")\n",
    "\n",
    "        self.now_action = action\n",
    "        self.prev_action = action\n",
    "        # self.prev_yes_share = self.now_yes_share\n",
    "        self.prev_env_index = deepcopy(self.now_env_index)\n",
    "        self.prev_cash = self.cash\n",
    "        self.prev_share = self.share\n",
    "        self.prev_pv = self.pv\n",
    "\n",
    "        # if len(self.q_dict) > 20000:\n",
    "        #     self.update_q_model()\n",
    "\n",
    "        try:\n",
    "            self.now_env_index, self.now_row = self.iter_env.next()\n",
    "        except StopIteration:\n",
    "            pass\n",
    "            # print(\"End of data.\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # if reward < 0:\n",
    "        #     self.penalty = True\n",
    "\n",
    "        try:\n",
    "            _ = self.reward\n",
    "        except AttributeError:\n",
    "            print(\"No reward yet...0 assigned.\")\n",
    "            self.reward = 0\n",
    "        # print \"ChimpBot.update(): Action: {0} at Price: {1}, Cash: {2}, Num_Share: {3}, Cash + PV = {4}, Reward = {5}\".format(action, self.now_row[-1], self.cash, self.share, self.cash + self.pv, self.reward)  # [debug]\n",
    "        # print('Portfolio + Cash: {}'.format(self.cash + self.pv))\n",
    "        # print(\"================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-109-7f0a073d3d3d>, line 38)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-109-7f0a073d3d3d>\"\u001b[0;36m, line \u001b[0;32m38\u001b[0m\n\u001b[0;31m    dfTrain.ix[:, :-1] = (dfTrain.ix[:, :-1] - dfTrain.ix[:, :-1].mean()) / dfTrain.ix[:, :-1].max() - dfTrain.ix[:, :-1].min())\u001b[0m\n\u001b[0m                                                                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def main_simulate():\n",
    "# Initiating data and the chimp\n",
    "    start_date = test_phase_data.index[0]\n",
    "    end_date = test_phase_data.index[-1]\n",
    "    \n",
    "    global data_full\n",
    "    dfFull = data_full\n",
    "    train_size = 21 * 8\n",
    "    batch_size = 7\n",
    "    date_range = test_phase_data.index[:] # Using 7 months of data to predict one month\n",
    "    print(date_range)\n",
    "    \n",
    "    batch_count = 0\n",
    "        \n",
    "    cash = 1000\n",
    "    share = 0\n",
    "    pv = 0\n",
    "    now_yes_share = 0\n",
    "\n",
    "    for batch in range(len(test_phase_data) // batch_size):\n",
    "        \n",
    "#     for date in date_range:\n",
    "        batch_count += 1\n",
    "        print(\"Batch {}\".format(batch_count))\n",
    "\n",
    "        try:\n",
    "            dfTest = dfFull.ix[test_phase_data.index[batch * batch_size]:test_phase_data.index[batch * batch_size + batch_size - 1]]\n",
    "        except IndexError:\n",
    "            dfTest = dfFull.ix[test_phase_data.index[batch * batch_size]:test_phase_data.index[-1]]\n",
    "        \n",
    "        (u,) = dfFull.index.get_indexer_for([test_phase_data.index[batch * batch_size]])\n",
    "\n",
    "        dfTrain = dfFull.iloc[u - (train_size):u]\n",
    "        \n",
    "        # Normalization\n",
    "        dfTrain.ix[:, :-1] = (dfTrain.ix[:, :-1] - dfTrain.ix[:, :-1].mean()) / dfTrain.ix[:, :-1].max() - dfTrain.ix[:, :-1].min())\n",
    "        dfTest.ix[:, :-1] = (dfTest.ix[:, :-1] - dfTrain.ix[:, :-1].mean()) / dfTrain.ix[:, :-1].max() - dfTrain.ix[:, :-1].min())\n",
    "\n",
    "        pca_dim = 246\n",
    "        pca = PCA(n_components=pca_dim)\n",
    "        pca.fit(dfTrain.ix[:, :-1])\n",
    "\n",
    "        chimp_train = ChimpBot(dfTrain)\n",
    "\n",
    "        for i in range(1500):\n",
    "            for l in range(len(chimp_train.env)):\n",
    "                # print(\"Train Round {0}-{1}\".format(i + 1, l + 1))\n",
    "                chimp_train.update()\n",
    "            chimp_train.reset()\n",
    "\n",
    "        # Test the Chimp!\n",
    "        q_df = deepcopy(chimp_train.q_df)\n",
    "        q_dict = deepcopy(chimp_train.q_dict)\n",
    "        q_reg = deepcopy(chimp_train.q_reg)\n",
    "\n",
    "        try:\n",
    "            _ = chimp_test\n",
    "        except NameError:\n",
    "            print(\"First time running...\")\n",
    "        else:\n",
    "            cash = chimp_test.cash\n",
    "            share = chimp_test.share\n",
    "            pv = chimp_test.pv\n",
    "            now_yes_share = chimp_test.now_yes_share\n",
    "\n",
    "        chimp_test = ChimpBot(dfTest, cash=cash, share=share, pv=pv, now_yes_share=now_yes_share)\n",
    "\n",
    "        chimp_test.q_df = deepcopy(q_df)\n",
    "        chimp_test.q_dict = deepcopy(q_dict)\n",
    "        chimp_test.q_reg = deepcopy(q_reg)\n",
    "        chimp_test.epsilon = 0\n",
    "\n",
    "        # Pass the cheatsheet to the next chimp\n",
    "        try:\n",
    "            chimp_test.prev_states = prev_states\n",
    "            chimp_test.now_action = now_action\n",
    "            chimp_test.prev_action = prev_action\n",
    "            chimp_test.prev_yes_share = prev_yes_share\n",
    "            chimp_test.reward = reward\n",
    "            chimp_test.prev_cash = prev_cash\n",
    "            chimp_test.prev_share = prev_share\n",
    "            chimp_test.prev_pv = prev_pv\n",
    "            chimp_test.prev_env_index = prev_env_index\n",
    "\n",
    "        except UnboundLocalError:\n",
    "            print(\"No cheatsheet to pass over yet...no worries!\")\n",
    "\n",
    "        for l in range(len(chimp_test.env)):\n",
    "            # print(\"Train Round {0}-{1}\".format(i + 1, l + 1))\n",
    "            chimp_test.update()\n",
    "                \n",
    "        # Create cheatsheet for the next chimp\n",
    "        prev_states = chimp_test.prev_states\n",
    "        now_action = chimp_test.now_action\n",
    "        prev_action = chimp_test.prev_action\n",
    "        prev_yes_share = chimp_test.prev_yes_share\n",
    "        prev_env_index = chimp_test.prev_env_index\n",
    "        reward = chimp_test.reward\n",
    "        prev_cash = chimp_test.prev_cash\n",
    "        prev_share = chimp_test.prev_share\n",
    "        prev_pv = chimp_test.prev_pv\n",
    "\n",
    "        global action_lists\n",
    "        action_lists.append(chimp_test.action_list)\n",
    "        \n",
    "        global pv_history_list\n",
    "        pv_history_list.append(chimp_test.cash + chimp_test.pv)\n",
    "        \n",
    "        if (batch + 1) % 3 == 0:\n",
    "            print(pv_history_list)\n",
    "        \n",
    "    print(pv_history_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-faacc422734f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpca_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m246\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpca_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlast_training_day\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# all data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_features' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# PCA Definition\n",
    "# feature_days = 21 * 6 = 126\n",
    "# n = 271: 0.96 <-- goldilock 1\n",
    "# n = 130: 0.895 <-- goldilock 2\n",
    "# Going with n = 246\n",
    "pca_dim = 246\n",
    "pca = PCA(n_components=pca_dim)\n",
    "pca.fit(df_features[:last_training_day]) # all data\n",
    "\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "# print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(\"Running PCA took {} seconds\".format(time.time() - start_time))\n",
    "\n",
    "\n",
    "# PCA transformation\n",
    "cp_imp = pca.explained_variance_ratio_\n",
    "cp_imp = pd.Series(cp_imp)\n",
    "cp_imp_cum = cp_imp.cumsum()\n",
    "cp_imp_cum.plot()\n",
    "\n",
    "df_features_pca = pca.transform(df_features)\n",
    "df_features_pca = pd.DataFrame(data=df_features_pca)\n",
    "df_features_pca['Date'] = df_features.index\n",
    "df_features_pca.set_index(df_features_pca['Date'], inplace=True)\n",
    "del df_features_pca.index.name\n",
    "del df_features_pca['Date']\n",
    "\n",
    "# Normalization post PCA\n",
    "df_features_pca = (df_features_pca - df_features_pca[:last_training_day].mean()) / (df_features_pca[:last_training_day].max() - df_features_pca[:last_training_day].min())\n",
    "\n",
    "# Reconstruct dataset\n",
    "df_full = df_features_pca\n",
    "df_full = df_features_pca['Trade Price'] = df_labels\n",
    "df_full = df_features_pca\n",
    "display(df_full.head())\n",
    "\n",
    "\n",
    "\n",
    "# Start simulation for the chimp\n",
    "num_iter = 1500\n",
    "day_count = 0\n",
    "pv_history_list = []\n",
    "\n",
    "chimp = ChimpBot(df_full)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(num_iter):\n",
    "    for l in range(len(chimp.env)):\n",
    "        chimp.update()\n",
    "    pv_history_list.append(chimp.cash + chimp.pv)\n",
    "    print(pv_history_list[-1])\n",
    "    chimp.reset()\n",
    "    \n",
    "print(\"{0} rounds of training took {1} seconds\".format(num_iter, time.time() - start_time))\n",
    "\n",
    "\n",
    "# Convert Q-Table to Dataframe from trained chimp (full)\n",
    "result_dict = defaultdict(list)\n",
    "for index, row in chimp.q_dict_analysis.iteritems():\n",
    "    for i in range(len(chimp.q_dict_analysis.keys()[0])):\n",
    "        column_name = 'col' + str(i + 1)\n",
    "        result_dict[column_name].append(index[i])\n",
    "    result_dict['Q'].append(chimp.q_dict_analysis[index][0])\n",
    "    result_dict['Date'].append(chimp.q_dict_analysis[index][1])\n",
    "\n",
    "q_df = pd.DataFrame(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
